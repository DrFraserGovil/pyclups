\documentclass[]{article}
\usepackage{JML}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{dsfont}
\usepackage[left=1in,right=1in]{geometry}
\title{Jack's Scratchpad}
\setlength\parskip{5pt}
\setlength\parindent{0pt}
\def\llangle{\left\langle}
\def\rrangle{\right\rangle}
\newcommand\E[1]{\llangle #1 \rrangle}
\usepackage{tikzsymbols}
\newcommand\T[1][i]{\mathcal{T}_{#1}}
\def\a{\vec{a}_t}
\def\ai{\vec{a}_{t_i}}
\def\vi{\vec{v}_i}
\def\wi{\vec{w}}
\usepackage{bbm}
\begin{document}
	\maketitle
	\tableofcontents
	\section{Initialisation}

		In the case where $\vec{w}$ must be optimised, we must first choose an initial starting point, $\vec{w}_0$, for the starting optimisation. The closer this is to the optimal point, the quicker the optimiser will converge.

		In order to make this efficient, we rewrite the constraint vector $\vec{c}$ in the following fashion:
		\begin{equation}
			\vec{c}(\vec{w}) = \vec{\xi} + \psi(\vec{w})
		\end{equation}
		Here $\vec{\xi}$ contains both the equality constraints and any constant-offsets associated with the inequality constraints, such that we may then enforce the following conditions on $\vec{\psi}$:
		\begin{equation}
			\left[ \vec{\psi}(\vec{w}) \right]_i  \begin{cases}
					= 0 & \text{if $i$ exact constraint}
					\\
					\geq 0 & \text{else}
				\end{cases}
		\end{equation}
		For example, if condition $j$ is that $x_j \geq -4$, then $\xi_j = -4$ and $\psi_j = \exp(w_j)$. We also limit ourselves to the case where $\vec{w} = \psi^{-1}(\vec{c} - \vec{\xi})$ exists. Note that this is not a limitation on our general method, but rather a choice made for efficient initialisation.

		The algorithm for determining the initialisation point is then:
		\begin{enumerate}
			\item Compute $\{ \vec{a}^\text{BLUP} \}$ and hence $\hat{\vec{Z}}^\text{blup}$: the predictors using the normal BLUP algorithm
			\item Let $\tilde{\vec{c}} = B \vec{p}_t = \vec{\xi} + \tilde{\vec{\varphi}}$
			\item Project onto the constraint-meeting surface:
			$$ \varphi_j = \begin{cases} \tilde{\varphi}_j & \text{if } \tilde{\varphi}_j \geq 0
				\\
				0 & \text{else} \end{cases}$$
			\item Set $\vec{w}_0 = \psi^{-1}\left(\varphi_j\right)$
		\end{enumerate}
		In practice, a small amount of numerical tolerance might be required (setting a $\varphi_j =0$ when $\psi^{-1} = \ln(\varphi)$ is not numerically stable), so at step 3 we suggest setting $\varphi_j = \epsilon$, some very small numerical quantity.

		\subsection{Comments on Initialisation}

			This method of initialisation is a na\"ive projection from the BLUP onto the space of constraint-obeying functions. In some simple cases, this projection is in fact equal to the global maximum: the case of positive functions, for example - the na\"ive projection truncates the BLUP to be equal to 0 wherever the BLUP would become negative, which is exactly the global solution. 
			
			In some pathological cases, however, this projection might lead to a function extremely far away from both the global maximum and the BLUP: consider the case of a BSCLUP constrained to be monotonically increasing, but where the BLUP is monotonically \textit{decreasing}. In this case, the projection of $\vec{w}_0$ would result in a flat line at the height of $Z^{BLUP}_0$ -- a rather significant deviation, and unlikely to be close to the optimum.

			Experimentally, we find that this initialisation serves as a good initial \textit{ansatz} as to the location of the optimum point for most real-world applications.
			

	\section{Thoughts on Paper V2}
		I like the newest version of the paper a lot! Much easier to read in some of the key areas. Here are some thoughts:

	
		\begin{enumerate}
			\item I still don't like the name BSCLUP -- how about we meet halfway and go with CLUPS: \textit{Constrained Linear Unbiased Predictor-Sequences/Sets}? 
			\item Footnote 1 has a question in it. (`random variables $X$ and $Y$ is CLUP thoughts'). Not sure I understand the question -- seems fine to end after $Y$?
			\item The note about the BSCLP vs BSCLUP is very good -- I wonder if a similar note about the BLP is worthwhile at the start of Section 2 -- emphasising \textit{why} we care about this entity, something along the lines of:
			
			``The \textit{best linear predictor} (BLP) for $Z_t$ is the linear predictor $\hat{Z}_t^\text{BLUP}$ which minimises the MSE subject to no constraints, and therefore has the minimum MSE among all linear predictors. Mechanically, the derivation is similar to above, but with the important conceptual difference of using the second moment $R = ...$ instead of the covariance (right?)."
			\item I think rewording the opening sentence of section 3 might place the emphasis more on what we are trying to do (and why it matters), something like:
			
			``In the BLP and BLUP, each prediction is treated as an individual point, distinct from all others. In practice, however, we are often interested in constructing sets and sequences of predictions upon which we might wish to impose constraints. In the case of a set of predictors, we might wish to impose upper or lower bounds, whilst in the case of a sequence we might wish to impose constraints between individual predictions such as monotonicity. Such sequence-constraints are non-separable since we cannot optimise one prediction without potentially impacting another in the sequence, and so we are moved to consider predictor-sequences as entities in their own right."
			\item Worth noting in the BSCLUP /BSCLP note (which I like!) that the distinction is conceptual (moments vs covariances) as well?
			\item Just before eq. 32, I think it is incorrect to say that we limit ourselves to the case of linear constraints to make the derivatives analytically (trivially not the case: quadratic constraints still have analytical derivatives!) it is that the derivatives can be \textit{analytically solved to produce Eq. 52} 
			\item I have come up with a better way to say the bit about the KKT constraints:
			
			``Since there is no guarantee of convexity, standard approaches such as slack variables and the Karush-Kuhn-Tucker conditions are not always applicable. As a general solution we parameterize the constraints such that"

			\item The text above Eq. 38 is weirdly archaic, try \textit{The random vector $X$ can be decomposed as in Eq. 8...}
			\item I wrote down `should we maybe capitalise (In)Exact' -- make it an Important Property that draws the eye?
			\item After the description of item 1 of the itemised list of ways the gradient can be 0, it might be useful to direct readers straight to remark 6:
			``The first case holds.... (see Eq 40 \textbf{and remark 6})''?
			\item In 3.1 (just before Eq. 57), you bother to remind me that $B$ is of size $q\times m$, but not what $q$ and $m$ are -- worthwhile doing so, to prevent me flicking backwards and forwards
			\item I would say that the ending of the first part of 3.1 could be made more obvious if you explicitly listed the ways in which $BB^T$ can be rank deficient (as you do with the zero-gradient conditions):
			
			``If any two rows are linearly dependent (for example, if any two of $B_1, B_2$ and $B_3$ are equal) then $B$ is rank deficient and $BB^T$ is uninvertible. There are four possible causes of this behaviour
			\begin{enumerate}
				\item Contradictory constraints
				\item Redundant Constraints
				\item Excess constraints
				\item Homonym Constraints (\textbf{name?})
			\end{enumerate}
			These first two causes indicate that the statistician has formulated their problem poorly, whilst the final two can arise even from well-formulated statements, and may require some cunning of the part of the statistician to rewrite their conditions in an appropriate fashion.''

			\item I would maybe put the sums in `Contradictory Constraints' next to their text -- it reads a bit weirdly at the moment:
			
			``For example, we may not require that the sum of the elements of the BSCLUP be both zero ($\sum_i \hat{Z} = 0$) and one ($\sum_i \hat{Z} = 1$) since these are inconsistent.''

			Follow that same pattern through the rest? Maybe just my personal preference

			\item In `Excess Constraints' I would emphasise that this is not necessarily a `you gone messed up' problem -- it's obvious when expressed in this language that it fails, but not necessarily obvious that $>0$ and $\sum = 1$ should fail on these grounds. 
			
			\item `Other Constraints' -- don't like the name (I suggested homonyms above, and I will write a suggestion based on that name)
			
			``It is possible for $BB^T$ to be singular even when the constraints are well formed and neither contradictory, redundant nor in excess. This arises when the constraints are expressed as `homonyms' of a constraint which \textit{would} be contradictory or redundant - that is, a set of constraints $B_i = \sum_{j\neq i} \alpha_j B_j$ but $\vec{c}_i \neq \sum_{j\neq i} \alpha_j \vec{c}_j$, such that the constraint `sounds' the same, but has a different meaning.
			
			For example, we consider a BSCLUP of $m > 2$ elements, where the only constraint is that $0 \leq \hat{Z}_0 \leq 1$. In this case, it would be natural to write the $2\times m$ matrix $B$ as:
			\begin{align}
				\begin{split}
					B &= \begin{pmatrix}
						1 & 0 & \hdots & 0
						\\
						1 & 0 & \hdots & 0
					\end{pmatrix}
				\end{split}
			\end{align}
			And the associated $\vec{c}$ as
			\begin{align}
				\begin{split}
					\vec{c}(\vec{w}) = \begin{pmatrix}
						\exp(w_1)
						\\
						1 - \exp(w_2)
					\end{pmatrix}
				\end{split}
			\end{align}
		
		This is a well formulated, valid constraint with fewer constraints than predictions - and yet it is clear that $BB^T$ is uninvertible. We can understand why this is by considering the invalid constraint $0 \leq Z_0 \leq -1$, the resulting $B^\prime$ and $\vec{c}^\prime$ are:
		\begin{align}
			% \begin{split}
				B^\prime &= \begin{pmatrix}
					1 & 0 & \hdots & 0
					\\
					1 & 0 & \hdots & 0
				\end{pmatrix}
				\\
				\vec{c}^\prime(\vec{w})& = \begin{pmatrix}
					\exp(w_1)
					\\
					-1 - \exp(w_2)
				\end{pmatrix}
			% \end{split}
		\end{align}
		We can see that the only difference between our valid and invalid constraints were encapsulated within $\vec{c}$. From the perspective of $BB^T$, both valid and invalid constraints are identical - thus we say that the valid constraint is a \textit{homonym} of the invalid constraint. 

		In order to generate a valid $B$, it is necessary only to formulate $B$ and $\vec{c}$ in a way which breaks this relationship - one potential solution would be:
		\begin{align}
			B & = \begin{pmatrix}
				1 & 0 & \hdots & 0
			\end{pmatrix}
			\\
			\vec{c}(w) & = \begin{pmatrix}
				\frac{1}{1 + \exp(-w)}
			\end{pmatrix}
		\end{align}

		\item There is a block of text in the second paragraph of 4 -- the BSCLUP being of finite length = resolution dependent. I think this is way too important a facet of the theory to be put here (it has implications for the error bounds, for example) - I would suggest maybe giving it its own dedicated (sub)section earlier in the paper.
		\item In Eq. 83 I think you actually want $t_i$ instead of $i$ -- you've implicitly assumed a) symmetry and b) ordering of the prediction points!
		\item In these examples, is it worth explicitly writing how these $B$/$c$ combinations result in the constraint being obeyed? I think it's a bit opaque as to how 85 and 86 result in monotonicity, but if we added in a line which said:
		\begin{equation}
			\hat{Z}_i = \hat{Z}_{i-1} + e^{z_i}
		\end{equation}
		Then it might be obvious how to go from a to b.

		\end{enumerate}

	\section{Prediction Errors}
		
		\subsection{Why the BLUP Approach doesn't work}
			
			The approach in standard BLUP texts is to simply use that the prediction error is (approximately -- some assumptions needed if I recall?) equal to the MSE evaluated at the optimum.

			This, however, utilises the assumption that each of the prediction points is independent; an assumption that does not follow through with the BSCLUP. We have emphasised that the BSCLUP prediction is on the \textit{entire} sequence/series of points - and hence any associated error must be computed on a global scale. 

			Simply put, it does not make sense to think about the error associated with just one point, when moving that point might have an impact on subsequent points (i.e., it is \textit{impossible} to move a point upwards in a monotonic predictor-series if the subsequent point already has the same prediction value, as this would violate the constraint.) 
			
			This concern is not merely limited to the predictor-sequences, as predictor-series also violate the assumptions that allow the MSE to be used; a trivial example would be the error on a predictor-series constrained to be non-negative, but which is predicted to be equal to zero. It is evident that a symmetric error around $Z = 0$ would not be representative of the predictor error at that point.
			
			We must therefore lend slightly more care and attention to our errors.
			
		\subsection{The MCMC Approach}

			Errors on sequences naturally lend themselves to an MCMC-style approach, as this provides a natural way to explore the intercorrelation between the sequence/series.

			In an ideal scenario, we would simply vary the predictor values, $\{\hat{Z}_\text{clup}\}$, and use this to generate a score $\mathcal{L}$ which the MCMC engine could explore. This faces two major problems:
			\begin{enumerate}
				\item The score function $\mathcal{L}$ is expressed in terms of $\{{\vec{a}}\}$, but $\hat{Z}$ and $\vec{a}$ are related through a non-invertible dot-product.
				\item With complex constraints, the majority of proposed variations to $\hat{Z}$ would be invalid, and hence the MCMC engine would not be able to produce a reliable chain.
			\end{enumerate}

			We must therefore run the MCMC engine in $\vec{a}$-space; which has the unfortunate by-product of being much higher-dimensional, and therefore has a higher autocorrelation length. However, blindly proposing a new $\vec{a}$ falls afoul of point 2) raised above, namely that the majority of the time, the resulting predictions will not be valid. 


			I therefore propose 4 potential algorithms for generating a valid MCMC chain.

			\subsubsection*{Algorithm 1: ``Fuck You, Markov, You Don't Know Me''}
				
				This algorithm is simple: any proposed $\{\vec{a}\}$ which violate the constraints is given a score of $-\infty$, and the rest is left up to the MCMC engine to handle. 

				This \textit{might} work in some of the inequality cases -- it almost certainly won't work in exact constraints (i.e. the probability of the MCMC generating a curve with an integral equal to 1 (within machine precision) is vanishingly small).

				I do not recommend this, but it is technically an option.

			\subsubsection*{Algorithm 2: ``Exactitude''}

				In this case, we treat the variation as happening on the space of $\{a_\text{nqblup} \}$ (nqBLUP = not-quite-best LUP, since we have varied it away from the optimum!). If the constraints were exact, then this is almost identical to simply varying the $\{\vec{a}\}$, you simply have to correct the predictor using the BSCLUP identity. If the constraints are inexact, then for each proposed $\{ a_\text{nqblup}\}$ we compute the exact value of $\vec{c}$ which optimises the predictor; we then have a means of associating a variational score to a predictor which is away from the mean, but which is guaranteed to obey the correct behaviour. 

				This is probably the most theoretically justifiable algorithm; the variables within $\vec{w}$ were always a fiction and so 'optimising them away' to produce the 'optimised-variation' seems like the best approach. 

				The downside is that -- aside from exact constraints and certain trivial cases -- this is computationally very costly, and will take a vast amount of computing power to produce meaningful results.
				
			\subsubsection*{Algorithm 3: ``Dual Variation''}

				It is clear that the MCMC must vary $\vec{a}_\text{nqblup}$ in order to produce meaningful results - however, we might take objection to the optimisation of $\vec{w}$ which the ``Exactitude'' method - firstly on practical grounds, and secondly on the idea that we are explicitly varying \textit{away} from the optimum -- so why do we not also vary $\vec{w}$\footnote{I don't know if I believe this, but would be interested in some thoughts!}?

				In this case, we form a composite vector $\{\vec{a}_\text{nqblup}, \vec{w}\}$ such that for each variation we can construct a $\vec{c}$, and then through the BSCLUP identity a $\vec{a}_\text{nqBSCLUP}$ and hence a score.

				The downside of this is that:
				\begin{itemize}
					\item We might argue the opposite way and say that unoptimised $\vec{w}$ values are meaningless
					\item This increases the number of dimensions (potentially up to twice as many), and so increases the autocorrelation time.
				\end{itemize}

			\subsubsection*{Algorithm 4: `Eh, Close Enough'}

				This final algorithm works similarly to Algorithm 2, except that no direct optimisation is involved. After proposing a new $\{\vec{a_\text{nqblup}}\}$, you then perform the Initialisation Projection:

				\begin{enumerate}
					\item Compute $\vec{\hat{\vec{Z}}}^\text{nqblup}$ using the normal BLUP algorithm
					\item Let $\tilde{\vec{c}} = B \vec{\hat{\vec{Z}}}^\text{nqblup} = \vec{\xi} + \tilde{{\varphi}}(\vec{w})$
					\item Project onto the constraint-meeting surface:
					$$ \varphi_j = \begin{cases} \tilde{\varphi}_j & \text{if } \tilde{\varphi}_j \geq 0
						\\
						0 & \text{else} \end{cases}$$
					\item Then set $\vec{c}^\prime = \vec{\xi} + \vec{\varphi}$
					\item Use $\{\vec{a}_\text{nqblup}\}$ and $\vec{c}^\prime$ to construct a $\{\vec{a}_\text{nqbsclup}\}$
				\end{enumerate}

				This guarantees that all proposed $\{\vec{Z}\}$ obey the constraints, however the projection performed is somewhat naive and may sometimes be far away from the optimum. 

				However, since we are varying $\vec{a}_\text{nqblup}$ freely, it can move very far away from the optimum, and so it is possible to generate arbitrary constraint-obeying $\vec{a_\text{bsclup}}$ (i.e., although the projection of $\vec{a}_\text{blup}$ is not guaranteed to be near the optimum, if we set $\vec{a}_\text{nqblup} = \vec{a}_\text{bsclup}$, the projection would trivially be equal to $\vec{a}_\text{bsclup}$, and therefore small variations from this position will also be projected into small variations from the optimum.)

				This has the benefit of being able to explore arbitrary predictors (given enough time), without producing too many additional dimensions -- the downside is that since the projections may make many $\vec{a}_\text{nqblup}$ produce the same $\vec{a}_\text{bsclup}$ (and hence the same score), the MCMC might think it has redundant dimensions, get confused, or otherwise have an excessively high autocorrelation time as it struggles to find which parameters are meaningful.
	\newpage
	\section{Prediction Errors, Redux}

		After attempting to generate a suitable MCMC chain using the above methodologies, it becomes clear rather quickly that the method will probably take a ludicrously long time to converge -- the dimensionality of the problem is equal to $m\times N$ where $m$ is the number of predictions and $N$ is the number of observables. 

		This is because we limited ourselves to the theoretically more justifiable case of varying only $\vec{a}$, since we have no direct means of turning a set of $\vec{Z}$s into a MSE score. 
		
		\textit{Except we do}.

		If we take the optimum $\vec{a}_\text{blup}$ and subject it to the constraint that $\vec{Z} = \vec{p}$, some proposed set of predictor points, then the CLUPS identity will act to project $\vec{a}_\text{blup}$ into the space where a) $\vec{Z}$ is equal to the desired value and b) the MSE is at a minimum for that desired prediction. Item b) is a corollary to the fact that our projection is a minimum-distance projection with the MSE as the measure.

		I therefore propose an alternative MCMC mode where we perform the following algorithm:
		\begin{enumerate}
			\item Propose a set of predictions, $\vec{p}$
			\item Via the Initialisation Projection, transform $\vec{p}$ into a constraint-obeying prediction. I.e. given a constraint matrix $B$ and a known vector-offset $\vec{\xi}$:
			\begin{align} 
				\vec{\phi} & = B \vec{p} - \vec{\xi}
				\\
				\psi_i & = \begin{cases} \phi_i &\text{if \textit{inexact} and } \phi_i > 0\\ 0 &\text{else} \end{cases}
				\\
				\vec{p}^\prime & = \vec{p} + B^T (BB^T)^{-1} \left(\vec{\xi} + \vec{\psi} - \vec{p} \right)
			\end{align}
			\item Perform a 'known predictor projection', using $B = I$ and $\vec{c} = \vec{p}^\prime$:
			\begin{equation}
				\vec{a}^\text{prop}_j = \vec{a}_j^\text{blup} + \frac{p^\prime_j - Z^\text{blup}_j}{\vec{D}^T K^{-1} \vec{X}} K^{-1} \vec{X}
			\end{equation}
			\item Compute the score:
			\begin{equation}
				\mathcal{L} = \sum_j \vec{a}^\text{prop}_j \cdot K \vec{a}^\text{prop}_j - 2 \vec{a}^\text{prop}_j \cdot \vec{k}_j
			\end{equation}
		\end{enumerate}
		As discussed in the `eh close enough' algorithm, the naive projection necessarily means a level of degeneracy (multiple $\vec{p}$ produce the same $\vec{p}^\prime$) and does not produce the optimal $\vec{p}^\prime$ given a $\vec{p}$ -- however since we are varying $\vec{p}$ freely and applying the real $\mathcal{L}$, this is more of a computational limitation than a theoretical one.

	\newpage

	\section{Some Whacky New Constraints}

		A common complaint from Ol' Man Amery is that we should not wish some of our constraints to be quite as....judicious...in their cuts as they sometimes are. For example, the 'positive' constraint simply cuts the BLUP predictor off at $z = 0$.

		If hard cuts are not what is desired, this implies that we have some intrinsic prior on the behaviour of the derivatives of the function and -- if that is the case -- we should therefore formulate some constraints which allow us to impose those priors on the predictor.

		\subsection{First Derivative}

			We have already made some moves to constrain the first order derivative with the monotonic constraint - this being the equivalent to the constraint that the derivative is everywhere positive. 

			The first-order gradient computed via forward-difference methods\footnote{Normally central difference is better - but that's for evaluating the gradient at a specific point -- what we're doing is (functionally) constraining the gradient between points, so feels like forward differences is more honest, right? I think it all comes out in the wash anyway.} is $\delta z_i = \frac{1}{t_{i+1} - t_i} \left(z_{i+1} - z_i \right)$, and so the matrix is therefore given by:
			\begin{equation}
				B^{(1)}_{ij}  = \delta_{i,j-1} - \delta_{ij}
			\end{equation}
			The matrix $B$ has size $N-1\times N$ - one degree of freedom remains. We have elected to keep the $\delta t$ out of the matrix since matrices with integer elements will be more numerically stable than those with elements of size $\delta t \ll 0$.

			Constraining the derivative now amounts to finding suitable values for $\vec{c}$.

			\subsubsection{Greater/Less Than}

				The case of single-sided bounds is trivial, and functionally identical to the monotonic constraint. Less Than constraints differ from greater than only by a multiplication by $-1$, and so we focus only on greater than. 

				If the gradient at $t = t_i$ must be greater than a value $d_i$, then (recalling that we are formulating $\vec{c}$ in terms of constant $\vec{\xi}$ and the function $\psi$):
				\begin{align}
					\xi_i &  = \delta t_i \times d_i
					\\
					[\psi(\vec{w})]_i & = \delta t_i \exp(w_i)
				\end{align}
				The vector $\vec{w}$ therefore trivially has dimensions $N-1$.

			\subsubsection{Bounded Between}

				The GT/LT cases amount to little more than extreme cases of monotonicity - perhaps a more interesting case is one where the gradient is bounded between two values $\ell_i$ and $u_i$ (especially where those values permit both negative and positive gradients).


				In this case, we have:
				\begin{align}
					\xi_i &  = \delta t_i \times \ell_i
					\\
					[\psi(\vec{w})]_i & = \delta t_i \frac{u_i - \ell_i}{1 + \exp(-w_i)}
				\end{align}

		
				
				

			\subsubsection{Bounded Outside}

				If we had a case where the gradient was $\delta z_i \geq u_i \cup \delta z_i \leq \ell_i$, I do not think this is the kind of constraint that we can reasonably manage.

				Two potential arguments (which I think amount to the same thing) for why this doesn't work:

				\begin{itemize}
					\item Concatenating constraints is  an AND operation. I do not think it is possible to formulate an equivalent OR in linear terms. That is because the constraint would functionally end up constraining $\left| \delta z_i - \frac{u_i - \ell_i}{2} \right|$, and the absolute value function is non-linear.
					\item We cannot formulate a continuous transformation $\psi(w)$ which would allow us to explore this space meaningfully. 
				\end{itemize}


			\subsubsection{Positive AND Bounded Constraint}

				Since constraining the gradient requires $N-1$ constraints for $N$ predictors, we cannot simply concatenate $B^{(1)}$ and $B^{\text{positive}}$ - this is a case which requires 'cunning'

				Constrainting the GT/LT or the Bounded-Between where $\text{sign}(\ell_i) = \text{sign}(u_i)$ case is simple - we only need to ensure that the first element (for monotonically increasing) or the final point (for monotonically decreasing) is greater than zero. This is, in fact, a simple case of concatenating a single positivity constraint on the relevant endpoint. 

				In the Bounded-Between case where $\ell_i$ and $u_i$ are of different signs (and hence the function is non-monotonic), things are more complex. It might be tempting to constraint the point $t_\text{extreme-blup}$, the smallest value of the BLUP predictor, however this is unworkable for a number of reasons (it has no guarantees of global enforcement).

				Instead, we constrain things as the following:
				\begin{align}
					B^{(1)+positive}_{ij} & = \mathds{1}_{N}
						\\
						\xi_i & = 0
						\\
						[\psi(\vec{w})]_i & = \begin{cases} \exp(w_{0})  & i = 0
							\\
							\mathfrak{l}_i + \frac{\mathfrak{u}_i - \mathfrak{l}_i}{1 + \exp(-w_i)} & \text{else}
							\end{cases}
						\\
						\mathfrak{u}_i & = u_i\delta t_i -\xi_i+ [\psi(\vec{w})]_{i-1}
						\\
						\mathfrak{l}_i & = \text{max}\left(0,{\ell_i \delta t_i} - \xi_i+ [\psi(\vec{w})]_{i-1} \right)
				\end{align}
				This is now an $N\times N$, fully constrained matrix and $\vec{w}$ is similarly $N$-dimensional. The transform is highly non-linear (and the derivatives will be unpleasant \& probably highly volatile!), but the constraint itself remains linear.

		
				\subsubsection{Computing the Derivatives}

					Perhaps the most unappealing part of this formulation is the necessity of computing the derivatives of $\vec{c}$ with respect to $\vec{w}$:

					\begin{equation}
						\div{\psi_i}{w_j} = \begin{cases} 
						\pdiv{\psi_j}{w_j} \prod_{k = j+1}^i \div{\psi_k}{\psi_{k-1}} & j \leq i
						\\
						0 & j > i
					 \end{cases}
					\end{equation}
					The components of this derivative can be found:
					\begin{align}
						\div{\psi_i}{w_i} &= \begin{cases} \exp(w_i) & i = 0 
							\\
							\frac{\mathfrak{u}_i - \mathfrak{l}_i}{(1 + \exp(-w_i))^2} \exp(-w_i) & \text{else}\end{cases}
							\\
							\begin{split}
							\div{\psi_{k}}{\psi_{k-1}} & = \pdiv{\psi_k}{\mathfrak{u}_k} \div{\mathfrak{u_k}}{\psi_{k-1}} + \pdiv{\psi_k}{\mathfrak{l}_k} \div{\mathfrak{l}_k}{\psi_{k-1}}
							\\
							& = \begin{cases}
								1 & \mathfrak{l}_k > 0
								\\
								\frac{1}{1 + e^{-w_{k}}} & \text{else}
							\end{cases}
							\end{split}
					\end{align}
		\subsection{Second Derivative}

			The second derivative case follows a fairly similar line of reasoning. The second derivative matrix is:
			
			\begin{equation}
				B^{(2)}_{ij} = \delta_{ij} + \delta_{i,j-2} - 2 \delta_{i,j-1}
			\end{equation}

			From here, the individual constraints -- greater than, less than and bounded-between are identical to the first derivative case, except that the relevant vectors have dimension $N-2$.

			\subsubsection{Positive \& Second Derivative}

				Positivity is much harder to enforce in the case of the second derivative where the values are constrained to be $\ell < 0 < u$- this is because the associated transform is significantly more complex - if a curve approaches $z = 0$, truncating the value at 0 (as was done in the first derivative case) results in a discontinuous derivative, and hence (highly likely) violates the second derivative bounds - in addition, since the gradient can fluctuate to be both positive and negative, there are many potential 'points of contact' with the line $z = 0$, and so great care must be taken with the transform. 
				
				We propose the following parameterisation which ensures that for a given position vector $\vec{w}$, the resulting curve $\vec{z}_{\vec{w}}(t)$ obeys the constraints.

				\begin{align}
					z_0 & = \exp(w_0)
					\\
					z_1 & = F(z_0,u \delta t^2) + \exp(w_1)
					\\
					z_i & = S(w_i,z_{i-2},z_{i-1},\ell\delta t^2,u\delta t^2) 
					\\
					F(z,d) & = z + d - \sqrt{d^2 + 2 d u}
					\\
					S(w,a,b,\ell^\prime,u^\prime) & = \mathfrak{l}(a,b,\ell^\prime,u^\prime) + \frac{\mathfrak{u}(a,b,u^\prime) - \mathfrak{l}(a,b,\ell^\prime,u^\prime)}{1 + \exp(-w)} 
					\\
					\mathfrak{u}(a,b,u^\prime) & = u^\prime + 2 b - a
					\\
					\mathfrak{l}(a,b,\ell^\prime,u^\prime) & = \text{max}\left(0,F(b,u^\prime), \ell^\prime + 2 b - a \right)
				\end{align}

				To explain:
				\begin{itemize}
					\item Under normal circumstances, if $z_{i-2}$ and $z_{i-1}$ are known, then, from the finite differences method for the second derivative:
					\begin{equation}
						\ell \leq \frac{z_i - 2 z_{i-1} + z_{i-2}}{\delta t^2} \leq u ~~~\Longrightarrow~~~\ell \delta t^2 + 2z_{i-1} - z_{i-2} \leq z_i \leq u\delta t^2 + 2z_{i-1} - z_{i-2} 
					\end{equation}
					The $S(w,z_{i-2},z_{i-1},l,u)$ function then acts to interpolate the value of $z_i$ between these two extremes, based on the value of $w$. The $\mathfrak{u}$ function simply computes the upper permitted bounds, for example.
					\item There are, however, two circumstances where this would cause a violation of our constraints:
					\begin{enumerate}
						\item If $z_i < 0$, we violate positivity
						
						Solution: the lower bound, $\mathfrak{l}$ can never be lower than 0:
						\begin{equation}
							\mathfrak{l} = \text{max}(0,\ell \delta t^2 + 2z_{i-1} - z_{i-2} )
						\end{equation}
						\item If $z_i < z_{i-1}$ by too much, then (since the gradient cannot increase by more than $u$), it becomes inevitable that the curve will intersect with $z = 0$ unless the $\pdiv{^2 z}{t^2} > u$ - and so when the truncation (see point i)) occurs, we violate our second derivative constraint.
						
						Solution: the lower bound, $\mathfrak{l}$ can never be lower than this 'point of no return' (PoNR). The PoNR can be found by computing the intersection of the quadratic curve $z = \frac{u}{2}(t - d)^2 + c$ (a quadratic with constant second derivative $u$). The value of $d$ can be determined by requiring that the gradient at $t = t_i$ is equal to $\frac{z_i - z_{i-1}}{\delta t}$, and the value of $c$ by requiring that the value of the function at $t = t_i$ is equal to $z_i$.

						The PoNR occurs when $c < 0$, which can be shown to occur when $z_i = z_{i-1} + u \delta t^2 - \sqrt{u^2 \delta t^4 + 2 z_{i-1} u \delta t^2} = F(z_{i-1},u \delta t^2)$. We see therefore that the function $F$ is therefore the PoNR function. We note that $0 \leq F(z_{i-1},a) < z_{i-1}$ (and is guaranteed to exist, since $z_{i-1} \geq 0$ and $u > 0$).

						Therefore:
						\begin{equation}
							\mathfrak{l} = \text{max}(0,F(z_i-1,u \delta t^2),\ell \delta t^2 + 2z_{i-1} - z_{i-2} )
						\end{equation}
						This is the definition given above. We also note that must also ensure that $z_1$ (which is otherwise unconstrained) does not pass this point - the parameterisation given permits it to have any value greater than the PoNR.

						One point to note is that the 'Point of No Return' is computed assuming a continuous forward projection - even though our sampling is necessarily on a finite grid. It might be possible that there would be no negative value predicted for some $0 < F(z,u^\prime) - \mathfrak{l} < \epsilon \ll 1$ as the prediction points fall either side of the minimum, however computing this would be costly and so it is easier to simply assume the continuous projection. Secondly, we also assume that the forward projection is infinite - there is no computation of if $d > t \forall t \in T^\prime$. This is again for ease of use, but does prohibit this method from predicting \textit{all} positive curves with bounded second derivatives \textit{on the specified domain} (the space is instead curves which are positive and have bounded second derivatives across the infinite domain).
					\end{enumerate}
				\end{itemize}

			\subsection{Monotonic \& Bounded Second Derivative}

				Given that the monotonicity constraint is more involved than positivity, it might initially seem that this constraint would be significantly more complex. However, it turns out that monotonicity in fact makes things considerably easier. The case where $l$ and $u$ have the same sign are trivial (they inherently imply monotonicity) - we now consider the case where $l < 0 < u$ and the function is monotonically increasing.

				We write our prediction points as:
				\begin{equation}
					z_i = z_{i-1} + q_i(w_i)
				\end{equation}
				The monotonicity constraint is that $q_i > 0$. In this case, the bounded gradient constraint reduces to:
				\begin{equation}
					l \leq \frac{z_{i} - 2 z_{i-1} + z_{i-2}}{\delta t^2} \leq u ~~~\Longrightarrow ~~~ l \delta t^2 + q_{i-1} \leq q_i \leq u \delta t^2 + q_{i-1}
				\end{equation}
				Recall that we require $q_i > 0$, so we add a truncation term:
				\begin{equation}
					\text{max}(0,l \delta t^2 + q_{i-1}) \leq q_i \leq u \delta t^2 + q_{i-1}
				\end{equation}
				Note that since this truncates the derivative (rather than the predictor value) we do not run into the PoNR problems discussed earlier. 

				It is therefore sufficient to write:
				\begin{align}
					B_{ij} & = \delta_{i,j-1}
					\\
					\psi_i(\vec{w}) & = \begin{cases}
						\exp(w_i) & i = 0
						\\ 
						S(w_j,\ell^\prime,u^\prime) & \text{else}
					\end{cases}
					\\
					S(w,l,u) & = l + \frac{u- l}{1 + \exp(-w)}
					\\
					\ell^\prime &= \text{max}(0,l \delta t^2 + \psi_{i-1})
					\\
					u^\prime & = l \delta t^2 + \psi_{i-1}
				\end{align}

				$B$ is an $N-1 \times N$ matrix.

				The derivatives of this function are as follows:
				\begin{align}
					\div{c_i}{w_j} = \div{\psi_i}{w_j} & = \begin{cases} 0 & i < j
						\\
						\div{\psi_j}{w_j} \prod_{k = j+1}^i \pdiv{\psi_k}{\psi_{k-1}} & i\geq j
					\end{cases}
					\\
					\div{\psi_j}{w_j} & = \begin{cases} \exp(w_j) & j = 0
						\\
						\frac{u - l}{(1 + \exp(-w_j))^2} \exp(-w_j) & \text{else}
					\end{cases}
					\\
					\pdiv{\psi_k}{\psi_{k-1}} & = \begin{cases} 1 & \ell^\prime > 0
						\\
						\frac{1}{1 + \exp(-w_k)} & \ell^\prime = 0\end{cases}
				\end{align}
			\subsubsection{Positive, Monotonic \& Bounded Second Derivative}

				As before, it is then trivial to extend this to the case where the function is positive - we simply need to constrain the first point to be positive, and then monotonicity takes care of the rest - and since we have one degree of freedom remaining, we can simply concatenate in a positivity constraint.

				\begin{align}
					B & = \mathds{1}_N
					\\
					\psi_i(\vec{w}) & = \begin{cases}
						\exp(w_i) & i = 0,1
						\\ 
						S(w_j,\ell^\prime,u^\prime) & \text{else}
					\end{cases}
					\\
					S(w,l,u) & = l + \frac{u- l}{1 + \exp(-w)}
					\\
					\ell^\prime &= \text{max}(0,l \delta t^2 + \psi_{i-1})
					\\
					u^\prime & = l \delta t^2 + \psi_{i-1}
				\end{align}
				(Note that though their forms are identical, $\psi_0 = \exp(w_0)$ and $\psi_1 = \exp(w_1)$ have different meanings - $z_0 = \psi_0$, whilst $z_1 = z_0 + \psi_1$.)

				The derivatives of this function are similar to the above, with a slight modification:
				\begin{align}
					\div{c_i}{w_j} = \div{\psi_i}{w_j} & = \begin{cases} 
						\div{\psi_j}{w_j} \prod_{k = j+1}^i \pdiv{\psi_k}{\psi_{k-1}} & i\geq j > 0
						\\
						\pdiv{\psi_j}{w_j} & i=j=0
						\\
						0 &\text{else}
					\end{cases}
					\\
					\div{\psi_j}{w_j} & = \begin{cases} \exp(w_j) & j = 0,1
						\\
						\frac{u - l}{(1 + \exp(-w_j))^2} \exp(-w_j) & \text{else}
					\end{cases}
					\\
					\pdiv{\psi_k}{\psi_{k-1}} & = \begin{cases} 1 & \ell^\prime > 0
						\\
						\frac{1}{1 + \exp(-w_k)} & \ell^\prime = 0\end{cases}
				\end{align}
\end{document}