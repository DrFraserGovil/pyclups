\documentclass[]{article}
\usepackage{JML}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{dsfont}
\usepackage[left=1in,right=1in]{geometry}
\title{Jack's Scratchpad}
\setlength\parskip{5pt}
\setlength\parindent{0pt}
\def\llangle{\left\langle}
\def\rrangle{\right\rangle}
\newcommand\E[1]{\llangle #1 \rrangle}
\usepackage{tikzsymbols}
\newcommand\T[1][i]{\mathcal{T}_{#1}}
\def\a{\vec{a}_t}
\def\ai{\vec{a}_{t_i}}
\def\vi{\vec{v}_i}
\def\wi{\vec{w}}
\usepackage{bbm}
\begin{document}
	\maketitle
	\tableofcontents
	\section{Initialisation}

		In the case where $\vec{w}$ must be optimised, we must first choose an initial starting point, $\vec{w}_0$, for the starting optimisation. The closer this is to the optimal point, the quicker the optimiser will converge.

		In order to make this efficient, we rewrite the constraint vector $\vec{c}$ in the following fashion:
		\begin{equation}
			\vec{c}(\vec{w}) = \vec{\xi} + \psi(\vec{w})
		\end{equation}
		Here $\vec{\xi}$ contains both the equality constraints and any constant-offsets associated with the inequality constraints, such that we may then enforce the following conditions on $\vec{\psi}$:
		\begin{equation}
			\left[ \vec{\psi}(\vec{w}) \right]_i  \begin{cases}
					= 0 & \text{if $i$ exact constraint}
					\\
					\geq 0 & \text{else}
				\end{cases}
		\end{equation}
		For example, if condition $j$ is that $x_j \geq -4$, then $\xi_j = -4$ and $\psi_j = \exp(w_j)$. We also limit ourselves to the case where $\vec{w} = \psi^{-1}(\vec{c} - \vec{\xi})$ exists. Note that this is not a limitation on our general method, but rather a choice made for efficient initialisation.

		The algorithm for determining the initialisation point is then:
		\begin{enumerate}
			\item Compute $\{ \vec{a}^\text{BLUP} \}$ and hence $\hat{\vec{Z}}^\text{blup}$: the predictors using the normal BLUP algorithm
			\item Let $\tilde{\vec{c}} = B \vec{p}_t = \vec{\xi} + \tilde{\vec{\varphi}}$
			\item Project onto the constraint-meeting surface:
			$$ \varphi_j = \begin{cases} \tilde{\varphi}_j & \text{if } \tilde{\varphi}_j \geq 0
				\\
				0 & \text{else} \end{cases}$$
			\item Set $\vec{w}_0 = \psi^{-1}\left(\varphi_j\right)$
		\end{enumerate}
		In practice, a small amount of numerical tolerance might be required (setting a $\varphi_j =0$ when $\psi^{-1} = \ln(\varphi)$ is not numerically stable), so at step 3 we suggest setting $\varphi_j = \epsilon$, some very small numerical quantity.

		\subsection{Comments on Initialisation}

			This method of initialisation is a na\"ive projection from the BLUP onto the space of constraint-obeying functions. In some simple cases, this projection is in fact equal to the global maximum: the case of positive functions, for example - the na\"ive projection truncates the BLUP to be equal to 0 wherever the BLUP would become negative, which is exactly the global solution. 
			
			In some pathological cases, however, this projection might lead to a function extremely far away from both the global maximum and the BLUP: consider the case of a BSCLUP constrained to be monotonically increasing, but where the BLUP is monotonically \textit{decreasing}. In this case, the projection of $\vec{w}_0$ would result in a flat line at the height of $Z^{BLUP}_0$ -- a rather significant deviation, and unlikely to be close to the optimum.

			Experimentally, we find that this initialisation serves as a good initial \textit{ansatz} as to the location of the optimum point for most real-world applications.
			

	\section{Thoughts on Paper V2}
		I like the newest version of the paper a lot! Much easier to read in some of the key areas. Here are some thoughts:

	
		\begin{enumerate}
			\item I still don't like the name BSCLUP -- how about we meet halfway and go with CLUPS: \textit{Constrained Linear Unbiased Predictor-Sequences/Sets}? 
			\item Footnote 1 has a question in it. (`random variables $X$ and $Y$ is CLUP thoughts'). Not sure I understand the question -- seems fine to end after $Y$?
			\item The note about the BSCLP vs BSCLUP is very good -- I wonder if a similar note about the BLP is worthwhile at the start of Section 2 -- emphasising \textit{why} we care about this entity, something along the lines of:
			
			``The \textit{best linear predictor} (BLP) for $Z_t$ is the linear predictor $\hat{Z}_t^\text{BLUP}$ which minimises the MSE subject to no constraints, and therefore has the minimum MSE among all linear predictors. Mechanically, the derivation is similar to above, but with the important conceptual difference of using the second moment $R = ...$ instead of the covariance (right?)."
			\item I think rewording the opening sentence of section 3 might place the emphasis more on what we are trying to do (and why it matters), something like:
			
			``In the BLP and BLUP, each prediction is treated as an individual point, distinct from all others. In practice, however, we are often interested in constructing sets and sequences of predictions upon which we might wish to impose constraints. In the case of a set of predictors, we might wish to impose upper or lower bounds, whilst in the case of a sequence we might wish to impose constraints between individual predictions such as monotonicity. Such sequence-constraints are non-separable since we cannot optimise one prediction without potentially impacting another in the sequence, and so we are moved to consider predictor-sequences as entities in their own right."
			\item Worth noting in the BSCLUP /BSCLP note (which I like!) that the distinction is conceptual (moments vs covariances) as well?
			\item Just before eq. 32, I think it is incorrect to say that we limit ourselves to the case of linear constraints to make the derivatives analytically (trivially not the case: quadratic constraints still have analytical derivatives!) it is that the derivatives can be \textit{analytically solved to produce Eq. 52} 
			\item I have come up with a better way to say the bit about the KKT constraints:
			
			``Since there is no guarantee of convexity, standard approaches such as slack variables and the Karush-Kuhn-Tucker conditions are not always applicable. As a general solution we parameterize the constraints such that"

			\item The text above Eq. 38 is weirdly archaic, try \textit{The random vector $X$ can be decomposed as in Eq. 8...}
			\item I wrote down `should we maybe capitalise (In)Exact' -- make it an Important Property that draws the eye?
			\item After the description of item 1 of the itemised list of ways the gradient can be 0, it might be useful to direct readers straight to remark 6:
			``The first case holds.... (see Eq 40 \textbf{and remark 6})''?
			\item In 3.1 (just before Eq. 57), you bother to remind me that $B$ is of size $q\times m$, but not what $q$ and $m$ are -- worthwhile doing so, to prevent me flicking backwards and forwards
			\item I would say that the ending of the first part of 3.1 could be made more obvious if you explicitly listed the ways in which $BB^T$ can be rank deficient (as you do with the zero-gradient conditions):
			
			``If any two rows are linearly dependent (for example, if any two of $B_1, B_2$ and $B_3$ are equal) then $B$ is rank deficient and $BB^T$ is uninvertible. There are four possible causes of this behaviour
			\begin{enumerate}
				\item Contradictory constraints
				\item Redundant Constraints
				\item Excess constraints
				\item Homonym Constraints (\textbf{name?})
			\end{enumerate}
			These first two causes indicate that the statistician has formulated their problem poorly, whilst the final two can arise even from well-formulated statements, and may require some cunning of the part of the statistician to rewrite their conditions in an appropriate fashion.''

			\item I would maybe put the sums in `Contradictory Constraints' next to their text -- it reads a bit weirdly at the moment:
			
			``For example, we may not require that the sum of the elements of the BSCLUP be both zero ($\sum_i \hat{Z} = 0$) and one ($\sum_i \hat{Z} = 1$) since these are inconsistent.''

			Follow that same pattern through the rest? Maybe just my personal preference

			\item In `Excess Constraints' I would emphasise that this is not necessarily a `you gone messed up' problem -- it's obvious when expressed in this language that it fails, but not necessarily obvious that $>0$ and $\sum = 1$ should fail on these grounds. 
			
			\item `Other Constraints' -- don't like the name (I suggested homonyms above, and I will write a suggestion based on that name)
			
			``It is possible for $BB^T$ to be singular even when the constraints are well formed and neither contradictory, redundant nor in excess. This arises when the constraints are expressed as `homonyms' of a constraint which \textit{would} be contradictory or redundant - that is, a set of constraints $B_i = \sum_{j\neq i} \alpha_j B_j$ but $\vec{c}_i \neq \sum_{j\neq i} \alpha_j \vec{c}_j$, such that the constraint `sounds' the same, but has a different meaning.
			
			For example, we consider a BSCLUP of $m > 2$ elements, where the only constraint is that $0 \leq \hat{Z}_0 \leq 1$. In this case, it would be natural to write the $2\times m$ matrix $B$ as:
			\begin{align}
				\begin{split}
					B &= \begin{pmatrix}
						1 & 0 & \hdots & 0
						\\
						1 & 0 & \hdots & 0
					\end{pmatrix}
				\end{split}
			\end{align}
			And the associated $\vec{c}$ as
			\begin{align}
				\begin{split}
					\vec{c}(\vec{w}) = \begin{pmatrix}
						\exp(w_1)
						\\
						1 - \exp(w_2)
					\end{pmatrix}
				\end{split}
			\end{align}
		
		This is a well formulated, valid constraint with fewer constraints than predictions - and yet it is clear that $BB^T$ is uninvertible. We can understand why this is by considering the invalid constraint $0 \leq Z_0 \leq -1$, the resulting $B^\prime$ and $\vec{c}^\prime$ are:
		\begin{align}
			% \begin{split}
				B^\prime &= \begin{pmatrix}
					1 & 0 & \hdots & 0
					\\
					1 & 0 & \hdots & 0
				\end{pmatrix}
				\\
				\vec{c}^\prime(\vec{w})& = \begin{pmatrix}
					\exp(w_1)
					\\
					-1 - \exp(w_2)
				\end{pmatrix}
			% \end{split}
		\end{align}
		We can see that the only difference between our valid and invalid constraints were encapsulated within $\vec{c}$. From the perspective of $BB^T$, both valid and invalid constraints are identical - thus we say that the valid constraint is a \textit{homonym} of the invalid constraint. 

		In order to generate a valid $B$, it is necessary only to formulate $B$ and $\vec{c}$ in a way which breaks this relationship - one potential solution would be:
		\begin{align}
			B & = \begin{pmatrix}
				1 & 0 & \hdots & 0
			\end{pmatrix}
			\\
			\vec{c}(w) & = \begin{pmatrix}
				\frac{1}{1 + \exp(-w)}
			\end{pmatrix}
		\end{align}

		\item There is a block of text in the second paragraph of 4 -- the BSCLUP being of finite length = resolution dependent. I think this is way too important a facet of the theory to be put here (it has implications for the error bounds, for example) - I would suggest maybe giving it its own dedicated (sub)section earlier in the paper.
		\item In Eq. 83 I think you actually want $t_i$ instead of $i$ -- you've implicitly assumed a) symmetry and b) ordering of the prediction points!
		\item In these examples, is it worth explicitly writing how these $B$/$c$ combinations result in the constraint being obeyed? I think it's a bit opaque as to how 85 and 86 result in monotonicity, but if we added in a line which said:
		\begin{equation}
			\hat{Z}_i = \hat{Z}_{i-1} + e^{z_i}
		\end{equation}
		Then it might be obvious how to go from a to b.

		\end{enumerate}

	\section{Prediction Errors}
		
		\subsection{Why the BLUP Approach doesn't work}
			
			The approach in standard BLUP texts is to simply use that the prediction error is (approximately -- some assumptions needed if I recall?) equal to the MSE evaluated at the optimum.

			This, however, utilises the assumption that each of the prediction points is independent; an assumption that does not follow through with the BSCLUP. We have emphasised that the BSCLUP prediction is on the \textit{entire} sequence/series of points - and hence any associated error must be computed on a global scale. 

			Simply put, it does not make sense to think about the error associated with just one point, when moving that point might have an impact on subsequent points (i.e., it is \textit{impossible} to move a point upwards in a monotonic predictor-series if the subsequent point already has the same prediction value, as this would violate the constraint.) 
			
			This concern is not merely limited to the predictor-sequences, as predictor-series also violate the assumptions that allow the MSE to be used; a trivial example would be the error on a predictor-series constrained to be non-negative, but which is predicted to be equal to zero. It is evident that a symmetric error around $Z = 0$ would not be representative of the predictor error at that point.
			
			We must therefore lend slightly more care and attention to our errors.
			
		\subsection{The MCMC Approach}

			Errors on sequences naturally lend themselves to an MCMC-style approach, as this provides a natural way to explore the intercorrelation between the sequence/series.

			In an ideal scenario, we would simply vary the predictor values, $\{\hat{Z}_\text{clup}\}$, and use this to generate a score $\mathcal{L}$ which the MCMC engine could explore. This faces two major problems:
			\begin{enumerate}
				\item The score function $\mathcal{L}$ is expressed in terms of $\{{\vec{a}}\}$, but $\hat{Z}$ and $\vec{a}$ are related through a non-invertible dot-product.
				\item With complex constraints, the majority of proposed variations to $\hat{Z}$ would be invalid, and hence the MCMC engine would not be able to produce a reliable chain.
			\end{enumerate}

			We must therefore run the MCMC engine in $\vec{a}$-space; which has the unfortunate by-product of being much higher-dimensional, and therefore has a higher autocorrelation length. However, blindly proposing a new $\vec{a}$ falls afoul of point 2) raised above, namely that the majority of the time, the resulting predictions will not be valid. 


			I therefore propose 4 potential algorithms for generating a valid MCMC chain.

			\subsubsection*{Algorithm 1: ``Fuck You, Markov, You Don't Know Me''}
				
				This algorithm is simple: any proposed $\{\vec{a}\}$ which violate the constraints is given a score of $-\infty$, and the rest is left up to the MCMC engine to handle. 

				This \textit{might} work in some of the inequality cases -- it almost certainly won't work in exact constraints (i.e. the probability of the MCMC generating a curve with an integral equal to 1 (within machine precision) is vanishingly small).

				I do not recommend this, but it is technically an option.

			\subsubsection*{Algorithm 2: ``Exactitude''}

				In this case, we treat the variation as happening on the space of $\{a_\text{nqblup} \}$ (nqBLUP = not-quite-best LUP, since we have varied it away from the optimum!). If the constraints were exact, then this is almost identical to simply varying the $\{\vec{a}\}$, you simply have to correct the predictor using the BSCLUP identity. If the constraints are inexact, then for each proposed $\{ a_\text{nqblup}\}$ we compute the exact value of $\vec{c}$ which optimises the predictor; we then have a means of associating a variational score to a predictor which is away from the mean, but which is guaranteed to obey the correct behaviour. 

				This is probably the most theoretically justifiable algorithm; the variables within $\vec{w}$ were always a fiction and so 'optimising them away' to produce the 'optimised-variation' seems like the best approach. 

				The downside is that -- aside from exact constraints and certain trivial cases -- this is computationally very costly, and will take a vast amount of computing power to produce meaningful results.
				
			\subsubsection*{Algorithm 3: ``Dual Variation''}

				It is clear that the MCMC must vary $\vec{a}_\text{nqblup}$ in order to produce meaningful results - however, we might take objection to the optimisation of $\vec{w}$ which the ``Exactitude'' method - firstly on practical grounds, and secondly on the idea that we are explicitly varying \textit{away} from the optimum -- so why do we not also vary $\vec{w}$\footnote{I don't know if I believe this, but would be interested in some thoughts!}?

				In this case, we form a composite vector $\{\vec{a}_\text{nqblup}, \vec{w}\}$ such that for each variation we can construct a $\vec{c}$, and then through the BSCLUP identity a $\vec{a}_\text{nqBSCLUP}$ and hence a score.

				The downside of this is that:
				\begin{itemize}
					\item We might argue the opposite way and say that unoptimised $\vec{w}$ values are meaningless
					\item This increases the number of dimensions (potentially up to twice as many), and so increases the autocorrelation time.
				\end{itemize}

			\subsubsection*{Algorithm 4: `Eh, Close Enough'}

				This final algorithm works similarly to Algorithm 2, except that no direct optimisation is involved. After proposing a new $\{\vec{a_\text{nqblup}}\}$, you then perform the Initialisation Projection:

				\begin{enumerate}
					\item Compute $\vec{\hat{\vec{Z}}}^\text{nqblup}$ using the normal BLUP algorithm
					\item Let $\tilde{\vec{c}} = B \vec{\hat{\vec{Z}}}^\text{nqblup} = \vec{\xi} + \tilde{{\varphi}}(\vec{w})$
					\item Project onto the constraint-meeting surface:
					$$ \varphi_j = \begin{cases} \tilde{\varphi}_j & \text{if } \tilde{\varphi}_j \geq 0
						\\
						0 & \text{else} \end{cases}$$
					\item Then set $\vec{c}^\prime = \vec{\xi} + \vec{\varphi}$
					\item Use $\{\vec{a}_\text{nqblup}\}$ and $\vec{c}^\prime$ to construct a $\{\vec{a}_\text{nqbsclup}\}$
				\end{enumerate}

				This guarantees that all proposed $\{\vec{Z}\}$ obey the constraints, however the projection performed is somewhat naive and may sometimes be far away from the optimum. 

				However, since we are varying $\vec{a}_\text{nqblup}$ freely, it can move very far away from the optimum, and so it is possible to generate arbitrary constraint-obeying $\vec{a_\text{bsclup}}$ (i.e., although the projection of $\vec{a}_\text{blup}$ is not guaranteed to be near the optimum, if we set $\vec{a}_\text{nqblup} = \vec{a}_\text{bsclup}$, the projection would trivially be equal to $\vec{a}_\text{bsclup}$, and therefore small variations from this position will also be projected into small variations from the optimum.)

				This has the benefit of being able to explore arbitrary predictors (given enough time), without producing too many additional dimensions -- the downside is that since the projections may make many $\vec{a}_\text{nqblup}$ produce the same $\vec{a}_\text{bsclup}$ (and hence the same score), the MCMC might think it has redundant dimensions, get confused, or otherwise have an excessively high autocorrelation time as it struggles to find which parameters are meaningful.
	\newpage
	\section{Prediction Errors, Redux}

		After attempting to generate a suitable MCMC chain using the above methodologies, it becomes clear rather quickly that the method will probably take a ludicrously long time to converge -- the dimensionality of the problem is equal to $m\times N$ where $m$ is the number of predictions and $N$ is the number of observables. 

		This is because we limited ourselves to the theoretically more justifiable case of varying only $\vec{a}$, since we have no direct means of turning a set of $\vec{Z}$s into a MSE score. 
		
		\textit{Except we do}.

		If we take the optimum $\vec{a}_\text{blup}$ and subject it to the constraint that $\vec{Z} = \vec{p}$, some proposed set of predictor points, then the CLUPS identity will act to project $\vec{a}_\text{blup}$ into the space where a) $\vec{Z}$ is equal to the desired value and b) the MSE is at a minimum for that desired prediction. Item b) is a corollary to the fact that our projection is a minimum-distance projection with the MSE as the measure.

		I therefore propose an alternative MCMC mode where we perform the following algorithm:
		\begin{enumerate}
			\item Propose a set of predictions, $\vec{p}$
			\item Via the Initialisation Projection, transform $\vec{p}$ into a constraint-obeying prediction. I.e. given a constraint matrix $B$ and a known vector-offset $\vec{\xi}$:
			\begin{align} 
				\vec{\phi} & = B \vec{p} - \vec{\xi}
				\\
				\psi_i & = \begin{cases} \phi_i &\text{if \textit{inexact} and } \phi_i > 0\\ 0 &\text{else} \end{cases}
				\\
				\vec{p}^\prime & = \vec{p} + B^T (BB^T)^{-1} \left(\vec{\xi} + \vec{\psi} - \vec{p} \right)
			\end{align}
			\item Perform a 'known predictor projection', using $B = I$ and $\vec{c} = \vec{p}^\prime$:
			\begin{equation}
				\vec{a}^\text{prop}_j = \vec{a}_j^\text{blup} + \frac{p^\prime_j - Z^\text{blup}_j}{\vec{D}^T K^{-1} \vec{X}} K^{-1} \vec{X}
			\end{equation}
			\item Compute the score:
			\begin{equation}
				\mathcal{L} = \sum_j \vec{a}^\text{prop}_j \cdot K \vec{a}^\text{prop}_j - 2 \vec{a}^\text{prop}_j \cdot \vec{k}_j
			\end{equation}
		\end{enumerate}
		As discussed in the `eh close enough' algorithm, the naive projection necessarily means a level of degeneracy (multiple $\vec{p}$ produce the same $\vec{p}^\prime$) and does not produce the optimal $\vec{p}^\prime$ given a $\vec{p}$ -- however since we are varying $\vec{p}$ freely and applying the real $\mathcal{L}$, this is more of a computational limitation than a theoretical one.

	\newpage

	\section{Some Whacky New Constraints}

		A common complaint from Ol' Man Amery is that we should not wish some of our constraints to be quite as....judicious...in their cuts as they sometimes are. For example, the 'positive' constraint simply cuts the BLUP predictor off at $z = 0$.

		If hard cuts are not what is desired, this implies that we have some intrinsic prior on the behaviour of the derivatives of the function and -- if that is the case -- we should therefore formulate some constraints which allow us to impose those priors on the predictor.

		\subsection{First Derivative}

			We have already made some moves to constrain the first order derivative with the monotonic constraint - this being the equivalent to the constraint that the derivative is everywhere positive. 

			The first-order gradient computed via forward-difference methods\footnote{Normally central difference is better - but that's for evaluating the gradient at a specific point -- what we're doing is (functionally) constraining the gradient between points, so feels like forward differences is more honest, right? I think it all comes out in the wash anyway.} is $\delta z_i = \frac{1}{t_{i+1} - t_i} \left(z_{i+1} - z_i \right)$, and so the matrix is therefore given by:
			\begin{equation}
				B^{(1)}_{ij}  = \delta_{i,j-1} - \delta_{ij}
			\end{equation}
			The matrix $B$ has size $N-1\times N$ - one degree of freedom remains. We have elected to keep the $\delta t$ out of the matrix since matrices with integer elements will be more numerically stable than those with elements of size $\delta t \ll 0$.

			Constraining the derivative now amounts to finding suitable values for $\vec{c}$.

			\subsubsection{Greater/Less Than}

				The case of single-sided bounds is trivial, and functionally identical to the monotonic constraint. Less Than constraints differ from greater than only by a multiplication by $-1$, and so we focus only on greater than. 

				If the gradient at $t = t_i$ must be greater than a value $d_i$, then (recalling that we are formulating $\vec{c}$ in terms of constant $\vec{\xi}$ and the function $\psi$):
				\begin{align}
					\xi_i &  = \delta t_i \times d_i
					\\
					[\psi(\vec{w})]_i & = \delta t_i \exp(w_i)
				\end{align}
				The vector $\vec{w}$ therefore trivially has dimensions $N-1$.

			\subsubsection{Bounded Between}

				The GT/LT cases amount to little more than extreme cases of monotonicity - perhaps a more interesting case is one where the gradient is bounded between two values $\ell_i$ and $u_i$ (especially where those values permit both negative and positive gradients).


				In this case, we have:
				\begin{align}
					\xi_i &  = \delta t_i \times \ell_i
					\\
					[\psi(\vec{w})]_i & = \delta t_i \frac{u_i - \ell_i}{1 + \exp(-w_i)}
				\end{align}

		
				
				

			\subsubsection{Bounded Outside}

				If we had a case where the gradient was $\delta z_i \geq u_i \cup \delta z_i \leq \ell_i$, I do not think this is the kind of constraint that we can reasonably manage.

				Two potential arguments (which I think amount to the same thing) for why this doesn't work:

				\begin{itemize}
					\item Concatenating constraints is  an AND operation. I do not think it is possible to formulate an equivalent OR in linear terms. That is because the constraint would functionally end up constraining $\left| \delta z_i - \frac{u_i - \ell_i}{2} \right|$, and the absolute value function is non-linear.
					\item We cannot formulate a continuous transformation $\psi(w)$ which would allow us to explore this space meaningfully. 
				\end{itemize}


			\subsubsection{Positive AND Bounded Constraint}

				Since constraining the gradient requires $N-1$ constraints for $N$ predictors, we cannot simply concatenate $B^{(1)}$ and $B^{\text{positive}}$ - this is a case which requires 'cunning'

				Constrainting the GT/LT or the Bounded-Between where $\text{sign}(\ell_i) = \text{sign}(u_i)$ case is simple - we only need to ensure that the first element (for monotonically increasing) or the final point (for monotonically decreasing) is greater than zero. This is, in fact, a simple case of concatenating a single positivity constraint on the relevant endpoint. 

				In the Bounded-Between case where $\ell_i$ and $u_i$ are of different signs (and hence the function is non-monotonic), things are more complex. It might be tempting to constraint the point $t_\text{extreme-blup}$, the smallest value of the BLUP predictor, however this is unworkable for a number of reasons (it has no guarantees of global enforcement).

				Instead, we constrain things as the following:
				\begin{align}
					B^{(1)+positive}_{ij} & = \mathds{1}_{N}
						\\
						\xi_i & = 0
						\\
						[\psi(\vec{w})]_i & = \begin{cases} \exp(w_{0})  & i = 0
							\\
							\mathfrak{l}_i + \frac{\mathfrak{u}_i - \mathfrak{l}_i}{1 + \exp(-w_i)} & \text{else}
							\end{cases}
						\\
						\mathfrak{u}_i & = u_i\delta t_i -\xi_i+ [\psi(\vec{w})]_{i-1}
						\\
						\mathfrak{l}_i & = \text{max}\left(0,{\ell_i \delta t_i} - \xi_i+ [\psi(\vec{w})]_{i-1} \right)
				\end{align}
				This is now an $N\times N$, fully constrained matrix and $\vec{w}$ is similarly $N$-dimensional. The transform is highly non-linear (and the derivatives will be unpleasant \& probably highly volatile!), but the constraint itself remains linear.

		
				\subsubsection{Computing the Derivatives}

					Perhaps the most unappealing part of this formulation is the necessity of computing the derivatives of $\vec{c}$ with respect to $\vec{w}$:

					\begin{equation}
						\div{\psi_i}{w_j} = \begin{cases} 
						\pdiv{\psi_j}{w_j} \prod_{k = j+1}^i \div{\psi_k}{\psi_{k-1}} & j \leq i
						\\
						0 & j > i
					 \end{cases}
					\end{equation}
					The components of this derivative can be found:
					\begin{align}
						\div{\psi_i}{w_i} &= \begin{cases} \exp(w_i) & i = 0 
							\\
							\frac{\mathfrak{u}_i - \mathfrak{l}_i}{(1 + \exp(-w_i))^2} \exp(-w_i) & \text{else}\end{cases}
							\\
							\begin{split}
							\div{\psi_{k}}{\psi_{k-1}} & = \pdiv{\psi_k}{\mathfrak{u}_k} \div{\mathfrak{u_k}}{\psi_{k-1}} + \pdiv{\psi_k}{\mathfrak{l}_k} \div{\mathfrak{l}_k}{\psi_{k-1}}
							\\
							& = \begin{cases}
								1 & \mathfrak{l}_k > 0
								\\
								\frac{1}{1 + e^{-w_{k}}} & \text{else}
							\end{cases}
							\end{split}
					\end{align}
		\subsection{Second Derivative}

			The second derivative case follows a fairly similar line of reasoning. The second derivative matrix is:
			
			\begin{equation}
				B^{(2)}_{ij} = \delta_{ij} + \delta_{i,j-2} - 2 \delta_{i,j-1}
			\end{equation}

			From here, the individual constraints -- greater than, less than and bounded-between are identical to the first derivative case, except that the relevant vectors have dimension $N-2$.

			\subsubsection{Positive \& Second Derivative}

				Positivity is much harder to enforce in the case of the second derivative where the values are constrained to be $\ell < 0 < u$- this is because the associated transform is significantly more complex - if a curve approaches $z = 0$, truncating the value at 0 (as was done in the first derivative case) results in a discontinuous derivative, and hence (highly likely) violates the second derivative bounds - in addition, since the gradient can fluctuate to be both positive and negative, there are many potential 'points of contact' with the line $z = 0$, and so great care must be taken with the transform. 
				
				We propose the following parameterisation which ensures that for a given position vector $\vec{w}$, the resulting curve $\vec{z}_{\vec{w}}(t)$ obeys the constraints.

				\begin{align}
					z_0 & = \exp(w_0)
					\\
					z_1 & = F(z_0,u \delta t^2) + \exp(w_1)
					\\
					z_i & = S(w_i,z_{i-2},z_{i-1},\ell\delta t^2,u\delta t^2) 
					\\
					F(z,d) & = z + d - \sqrt{d^2 + 2 d u}
					\\
					S(w,a,b,\ell^\prime,u^\prime) & = \mathfrak{l}(a,b,\ell^\prime,u^\prime) + \frac{\mathfrak{u}(a,b,u^\prime) - \mathfrak{l}(a,b,\ell^\prime,u^\prime)}{1 + \exp(-w)} 
					\\
					\mathfrak{u}(a,b,u^\prime) & = u^\prime + 2 b - a
					\\
					\mathfrak{l}(a,b,\ell^\prime,u^\prime) & = \text{max}\left(0,F(b,u^\prime), \ell^\prime + 2 b - a \right)
				\end{align}

				To explain:
				\begin{itemize}
					\item Under normal circumstances, if $z_{i-2}$ and $z_{i-1}$ are known, then, from the finite differences method for the second derivative:
					\begin{equation}
						\ell \leq \frac{z_i - 2 z_{i-1} + z_{i-2}}{\delta t^2} \leq u ~~~\Longrightarrow~~~\ell \delta t^2 + 2z_{i-1} - z_{i-2} \leq z_i \leq u\delta t^2 + 2z_{i-1} - z_{i-2} 
					\end{equation}
					The $S(w,z_{i-2},z_{i-1},l,u)$ function then acts to interpolate the value of $z_i$ between these two extremes, based on the value of $w$. The $\mathfrak{u}$ function simply computes the upper permitted bounds, for example.
					\item There are, however, two circumstances where this would cause a violation of our constraints:
					\begin{enumerate}
						\item If $z_i < 0$, we violate positivity
						
						Solution: the lower bound, $\mathfrak{l}$ can never be lower than 0:
						\begin{equation}
							\mathfrak{l} = \text{max}(0,\ell \delta t^2 + 2z_{i-1} - z_{i-2} )
						\end{equation}
						\item If $z_i < z_{i-1}$ by too much, then (since the gradient cannot increase by more than $u$), it becomes inevitable that the curve will intersect with $z = 0$ unless the $\pdiv{^2 z}{t^2} > u$ - and so when the truncation (see point i)) occurs, we violate our second derivative constraint.
						
						Solution: the lower bound, $\mathfrak{l}$ can never be lower than this 'point of no return' (PoNR). The PoNR can be found by computing the intersection of the quadratic curve $z = \frac{u}{2}(t - d)^2 + c$ (a quadratic with constant second derivative $u$). The value of $d$ can be determined by requiring that the gradient at $t = t_i$ is equal to $\frac{z_i - z_{i-1}}{\delta t}$, and the value of $c$ by requiring that the value of the function at $t = t_i$ is equal to $z_i$.

						The PoNR occurs when $c < 0$, which can be shown to occur when $z_i = z_{i-1} + u \delta t^2 - \sqrt{u^2 \delta t^4 + 2 z_{i-1} u \delta t^2} = F(z_{i-1},u \delta t^2)$. We see therefore that the function $F$ is therefore the PoNR function. We note that $0 \leq F(z_{i-1},a) < z_{i-1}$ (and is guaranteed to exist, since $z_{i-1} \geq 0$ and $u > 0$).

						Therefore:
						\begin{equation}
							\mathfrak{l} = \text{max}(0,F(z_i-1,u \delta t^2),\ell \delta t^2 + 2z_{i-1} - z_{i-2} )
						\end{equation}
						This is the definition given above. We also note that must also ensure that $z_1$ (which is otherwise unconstrained) does not pass this point - the parameterisation given permits it to have any value greater than the PoNR.

						One point to note is that the 'Point of No Return' is computed assuming a continuous forward projection - even though our sampling is necessarily on a finite grid. It might be possible that there would be no negative value predicted for some $0 < F(z,u^\prime) - \mathfrak{l} < \epsilon \ll 1$ as the prediction points fall either side of the minimum, however computing this would be costly and so it is easier to simply assume the continuous projection. Secondly, we also assume that the forward projection is infinite - there is no computation of if $d > t \forall t \in T^\prime$. This is again for ease of use, but does prohibit this method from predicting \textit{all} positive curves with bounded second derivatives \textit{on the specified domain} (the space is instead curves which are positive and have bounded second derivatives across the infinite domain).
					\end{enumerate}
				\end{itemize}

			\subsection{Monotonic \& Bounded Second Derivative}

				Given that the monotonicity constraint is more involved than positivity, it might initially seem that this constraint would be significantly more complex. However, it turns out that monotonicity in fact makes things considerably easier. The case where $l$ and $u$ have the same sign are trivial (they inherently imply monotonicity) - we now consider the case where $l < 0 < u$ and the function is monotonically increasing.

				We write our prediction points as:
				\begin{equation}
					z_i = z_{i-1} + q_i(w_i)
				\end{equation}
				The monotonicity constraint is that $q_i > 0$. In this case, the bounded gradient constraint reduces to:
				\begin{equation}
					l \leq \frac{z_{i} - 2 z_{i-1} + z_{i-2}}{\delta t^2} \leq u ~~~\Longrightarrow ~~~ l \delta t^2 + q_{i-1} \leq q_i \leq u \delta t^2 + q_{i-1}
				\end{equation}
				Recall that we require $q_i > 0$, so we add a truncation term:
				\begin{equation}
					\text{max}(0,l \delta t^2 + q_{i-1}) \leq q_i \leq u \delta t^2 + q_{i-1}
				\end{equation}
				Note that since this truncates the derivative (rather than the predictor value) we do not run into the PoNR problems discussed earlier. 

				It is therefore sufficient to write:
				\begin{align}
					B_{ij} & = \delta_{i,j-1}
					\\
					\psi_i(\vec{w}) & = \begin{cases}
						\exp(w_i) & i = 0
						\\ 
						S(w_j,\ell^\prime,u^\prime) & \text{else}
					\end{cases}
					\\
					S(w,l,u) & = l + \frac{u- l}{1 + \exp(-w)}
					\\
					\ell^\prime &= \text{max}(0,l \delta t^2 + \psi_{i-1})
					\\
					u^\prime & = l \delta t^2 + \psi_{i-1}
				\end{align}

				$B$ is an $N-1 \times N$ matrix.

				The derivatives of this function are as follows:
				\begin{align}
					\div{c_i}{w_j} = \div{\psi_i}{w_j} & = \begin{cases} 0 & i < j
						\\
						\div{\psi_j}{w_j} \prod_{k = j+1}^i \pdiv{\psi_k}{\psi_{k-1}} & i\geq j
					\end{cases}
					\\
					\div{\psi_j}{w_j} & = \begin{cases} \exp(w_j) & j = 0
						\\
						\frac{u - l}{(1 + \exp(-w_j))^2} \exp(-w_j) & \text{else}
					\end{cases}
					\\
					\pdiv{\psi_k}{\psi_{k-1}} & = \begin{cases} 1 & \ell^\prime > 0
						\\
						\frac{1}{1 + \exp(-w_k)} & \ell^\prime = 0\end{cases}
				\end{align}
			\subsection{Positive, Monotonic \& Bounded Second Derivative}

				As before, it is then trivial to extend this to the case where the function is positive - we simply need to constrain the first point to be positive, and then monotonicity takes care of the rest - and since we have one degree of freedom remaining, we can simply concatenate in a positivity constraint.

				\begin{align}
					B & = \mathds{1}_N
					\\
					\psi_i(\vec{w}) & = \begin{cases}
						\exp(w_i) & i = 0,1
						\\ 
						S(w_j,\ell^\prime,u^\prime) & \text{else}
					\end{cases}
					\\
					S(w,l,u) & = l + \frac{u- l}{1 + \exp(-w)}
					\\
					\ell^\prime &= \text{max}(0,l \delta t^2 + \psi_{i-1})
					\\
					u^\prime & = l \delta t^2 + \psi_{i-1}
				\end{align}
				(Note that though their forms are identical, $\psi_0 = \exp(w_0)$ and $\psi_1 = \exp(w_1)$ have different meanings - $z_0 = \psi_0$, whilst $z_1 = z_0 + \psi_1$.)

				The derivatives of this function are similar to the above, with a slight modification:
				\begin{align}
					\div{c_i}{w_j} = \div{\psi_i}{w_j} & = \begin{cases} 
						\div{\psi_j}{w_j} \prod_{k = j+1}^i \pdiv{\psi_k}{\psi_{k-1}} & i\geq j > 0
						\\
						\pdiv{\psi_j}{w_j} & i=j=0
						\\
						0 &\text{else}
					\end{cases}
					\\
					\div{\psi_j}{w_j} & = \begin{cases} \exp(w_j) & j = 0,1
						\\
						\frac{u - l}{(1 + \exp(-w_j))^2} \exp(-w_j) & \text{else}
					\end{cases}
					\\
					\pdiv{\psi_k}{\psi_{k-1}} & = \begin{cases} 1 & \ell^\prime > 0
						\\
						\frac{1}{1 + \exp(-w_k)} & \ell^\prime = 0\end{cases}
				\end{align}

			\subsection{Positive, Monotonic \& Bounded Second Derivative}

				This is, once again, gross - and once again $\ell < 0 < u$

				We once again use an iterative method, using $w_{j < i}$ to determine $z_i$. At each point, there are a number of considerations:
				\begin{itemize}
					\item At no point must $z_i$ be negative
					\item At no point must $z_i$ generate a gradient negative enough that $z_{j > i}$ will be forced to be negative
					\item At no point must $z_i$ be so large that the integral is forced to be greater than $\mathcal{I}$.
					\item At no point must $z_i$ be so small that the integral is forced to be less than $\mathcal{I}$.
				\end{itemize}
				These first two points we can already constrain, using the PoNR function. The second two constraints arise from the fact that we know what the sum of points must be equal to -- but since the movement of points is constrained by the curvature, it would be possible to make it impossible to reach the values required for the integral. 

				We define the running integral $R_i = \frac{1}{2} z_0 + \sum_{j = 1}^{i-1} z_i$, with the target value of $R_{N-1}$ being $\frac{\mathcal{I}}{\delta t}$

				\subsubsection{Undershooting}


					An undershoot occurs when a $z_i$ is chosen such that, even if the curve subsequently has constant curvature $u$, the integral is $I^\prime < \mathcal{I}$.	

					The integral can be approximated then as:
					\begin{align}
						I^\prime &  = R_i + \int_{t_i}^{t_{N-1}} \frac{u}{2} (t - d_i)^2 + c_i \mathrm d t
					\end{align}
					The values of $d_i$ and $c_i$ can be computed by equating the functional and derivative values:
					\begin{align}
						d_i & = t_i - \frac{z_i - z_{i-1}}{ u \delta t}
						\\
						c_i & = z_i  - \frac{(z_i - z_{i-1})^2}{2 u \delta t^2}
					\end{align}
					The integral is then given by $(\Delta t_i = t_{n-1} - t_i)$:
					\begin{equation}
						I^\prime = \delta t R_i + \Delta t_i z_i \left( 1 + \frac{\Delta t_i}{2 \delta t} \right) - \frac{\Delta t_i^2 z_{i-1}}{2 \delta t} + \frac{u \Delta t_i^3}{6}
					\end{equation}
					Undershooting occurs when $I^\prime < \mathcal{I}$, so we require:
					\begin{equation}
						z_i \geq z_\text{under} = \left(1 + \frac{\Delta t_i}{2\delta t}\right)^{-1} \left(\mathcal{I} - \delta t R_i + \frac{\Delta t_i^2 z_{i-1}}{2 \delta t} - \frac{u \Delta t_i^3}{6}\right)
					\end{equation}
					Since $z_{i-1}$ was also chosen subject to these conditions, it follows that $z_i^\text{undershoot} < z^\text{max}$ - i.e. so long as the first two points of the sequence are suitably chosen, all subsequent points will have a finite $z_\text{undershoot} \leq z \leq z_\text{max}$.


				\subsubsection{Overshooting}

					An overshoot occurs when a $z_i$ is chosen such that, even if the curve subsequently has curvature $\ell$ the integral is $I^\prime > \mathcal{I}$, OR, if the curve which would be required would cause the curve to go negative before $t_{N-1}$.

					Following the same logic as before, we find:
					\begin{equation}
						z_i \leq z_\text{over} = \left(1 + \frac{\Delta t_i}{2\delta t}\right)^{-1} \left(\mathcal{I} - \delta t R_i + \frac{\Delta t_i^2 z_{i-1}}{2 \delta t} - \frac{\ell \Delta t_i^3}{6}\right)
					\end{equation}

					However, there is another condition -- namely that the overshooting curve is not bounded by zero -- this forward projection might lead to us overshooting since negativity is impossible. We must therefore also ensure that $z_i \leq z_\text{zero}$. $z_\text{0}$ can be found by projecting \textit{backwards} a line with constant curvature $\ell$ which intersects $z = 0$ at $t = t_{N-1}$, but which has area $I- \delta t R_i$. If $z_i$ is ever above this line, then the overshooting curve will force $z_i < 0$. 

					The parameters of the back-projected line are $\frac{\ell}{2}\left[(t - q_i)^2 - (t_f - q_i)^2 \right]$ - this ensures the correct curvature and intersection. All that remains is to constrain $q_i$ by requiring the integral:
					\begin{align}
						I - \delta t R_i & = \int_{t_i}^{t_{N-1}} \frac{\ell}{2}\left[(t - q_i)^2 - (t_f - q_i)^2 \right]
						\\
						\frac{2(I - \delta t R_i)}{\ell} & = \frac{\Delta^3 t_i}{3} + 2 q_i( t_{N-1} \Delta t_i - \frac{\Delta^2 t_i}{2}) - t_{N-1}^2 \Delta t_i
					\end{align}
					Where $\Delta^n t_i = t_i^n - t_{N-1}^n$. This gives:
					\begin{align}
						q_i = \frac{1}{\Delta t_i^2} \left( \frac{2(I - \delta t R_i)}{\ell} - \frac{\Delta^3 t_i}{3} - t_N^2 \Delta t_i\right)
					\end{align}
					The maximum permitted value of $z$ is therefore found from:
					\begin{equation}
						z_\text{zero} = \frac{\ell}{2} \left( (t_i - q_i)^2 - (t_{N-1} - q_i)^2\right)
					\end{equation}
					We note that this somewhat violates the previous assumption about the PoNR which explicitly prohoibited the 'collision course' implied by $z_\text{zero}$. If we ever find a case where $z_\text{zero} < z_\text{PoNR}$, then we must take $z = z_\text{zero}$ - since this implies that the \textit{only} possible path forward is the direct collision course. 

					To summarise:

					At each point $i$, $z_i$ is bounded by:
					\begin{equation}
						\text{max}(0,z_\text{under},\text{min}(z_\text{zero},z_\text{PoNR}),\ell \delta t^2 + 2 z_{i-1} - z_{i-2}) \leq z_i \leq \text{min}(z_\text{over},z_\text{zero},u \delta t^2 + 2 z_{i-1} - z_{i-2})
					\end{equation}
	\newpage
	\section{Comments: Distribution Version}

		I think the paper is really coming together! I have gone over this with a fine-toothed comb so this is me being picky in lots of places.

		\begin{enumerate}
			\item c.f. my previous comment about the first paragraph -- how about augmenting it with something like:
			
			{\it ...and in particular for fitting curves to samples of computationally expensive black-box functions (Rasmussen and Williams 2006). {\color{red} Both the BLP and the BLUP are solutions to the following problem: g}iven a potentially noisy sample of a curve we wish to infer the value of that curve at an arbitrary point.... }

			Makes it obvious that you're still talking about the properties of the BLUP rather than moving onto something that \textit{we} are doing.

			\item Still in first para, you double-use `element' to refer to different things (elements in predictor space vs element of X) in a potentially ambiguous way. Maybe:
			
			{\it The set of predictors for every {\color{red} point in the predictor-space} then serves as the fitted curve. The BLP and BLUP for each {\color{red} prediction} are both weighted sums of the elements of the sample. In the case of the BLP the weights are chosen so as to minimize the mean-square error of prediction.}

			\item In second para, your list of constraints is maybe a little prescient, Muad'dib! Rather than just list off "here's what we're doing later", replace them with motiviations that lead to the constraints?
			
			{\it For example we may know that the function is a probability distribution function, in which case it must be positive and have a bounded integral. Known symmetries might require the function to be even, or strong priors on the underlying mechanics may lead us to requure a monotonic predictor, or one bounded by known curves.}

			\item Immediately after this, I would then add {\it {\color{red}In the normal BL(U)P, t}his knowledge goes unused....}
			\item You mention pairwise constraints from monotonicity -- also throw in a reference to, i.e. integrability which constrains the entire set of predictors simultaneously?
			\item You italicise 'subject to the constraint' wrt the BLUP in the first para, so I would do the same with the CLUPS: We minimize the \textit{total mean-square error} of the sequence of predictors \textit{\color{red}subject to these constraints}. 
			\item Eq. 15 is horrible to parse -- I would maybe fudge some of the bracket sizing/replace parans with square brackets to make the groupings easier to see!
			\item After the comment {\it``The BLUP for Zt exists if and only if m is contained by the span of the basis functions''} is it worth writing here (or anywhere) that this means that whenever we use a finite basis set we're making an approximation, but that this is generally OK? Otherwise we've written ourselves into a corner that we need to use as high dimensional bases as possible which does not end well!
			\item define GLS before you use it -- {\it the generalized least-squares (GLS) estimator for the mean.} I know it's obvious from context, but it's good practice.
			\item In section 2, make explicit the difference between $R$ and $K$. 
			\item In Eq. 23 there is a typo -- repeats $E(Z_t^2)$ twice - one should be $E(Z_t)^2$, right?
			\item I originally had a comment here about that after 37, needed to write $b^{\prime \prime}$ is concatenation of $[b,b^\prime]$ with dimensions $q = u + v$ and so on, but then found it on the next page, so that's great! I might move that section (starting from 42) up (to immediately after 37) -- just so all of the 'constraint stuff' is in one place, but I think that's a minor quibble.
			\item The comment about bounded $\vec{w}$ in the gradient discussion is almost there (but not quite -- it says $w$ is bounded which is the opposite!) -- I might tweak it to the following:
			
			{\it To interpret the remaining three cases we should note that our constraints restrict the
			parameter {\color{red} $\vec{c}$ to taking values within some subset of $V \in \mathbb{R}^q$, and our definition of $\psi$ required that this region be connected, and $\psi$ be within this region and differentiable for all $\vec{w}$ - as a result, $\pdiv{\psi}{w}$ must vanish as it approaches the boundary of $V$.  Therefore, the} second case holds when a constraint is satisfied...}

			\item Your wording that the {\it CLUPS differs from the set of BLUPs by the shortest random vector consistent with the constraints.} I think is a bit dodgy, since it implies that $ B \Delta = \vec{c}$, which isn't the case. I think what you mean is {\it The CLUPS is the set of vectors closest to the BLUPS which obeys the constraints}?
			\item Remark 6 could do with an addition (and constrained-BLUP $\to$ CLUPS for consistency):
			
			{\it The MSE of the constrained CLUPS is in general larger than that of the BLUP since the constraints prohibit the MSE from taking the smallest possible value. {\color{red}This is also true of the BLUP, for which the unbiasedness condition makes it `worse' than the BLP - the predictor which is defined as having the globally-minimal MSE}. This reflects the fact that we accept the constraints {\color{red} (and unbiasedness)} to be a better source of knowledge than the MSE.}
			
			\item Small addition to excess conditions:
			
			{\it Although it is obvious when expressed in our language that the concatenation of such constraints will fail \textcolor{red}{due to the matrix rank}....}

			\item Back to the cummax thing, I might just rearrange some things around:
			
			{\it {\color{red}This projection does not always lead to functions close to the optimum - in the case of a monotonically-constrained CLUPS, the initialisation projection is the cumulative maximum of the sequence of BLUPS - a non-optimum solution. In the pathological case of such a monotonically-increasing CLUPS where the BLUP is monotonically \textit{decreasing}, the CLUPS would predict $Z_{t_0}^\text{BLUP}$ for every value -- clearly extremely far from the optimum.}
			
			Nevertheless, we find experimentally that this initialization serves as a good ansatz for the optimum point in many real-world applications.}
			
			\item I hate 'much used' with a fiery passion that could consume a trillion suns.	
			
			\item In the resolution dependence section, I would add 'may': 
			
			{\it But in general a CLUPS of finite length, $\vec{Z}^{CLUPS}$, is not a sample of the random process ${Z}^{CLUPS}$ since the elements of $\vec{Z}^{CLUPS}$ \textcolor{red}{may} differ according to its length.}

			\item It might be worth simply stating that this occurs when your constraints are non-separable? I.e. Predictor-Sets are not resolution dependent, but Predictor-Sequences are. 
			
			\item When defining $\epsilon$, worth mentioning that this is only possible since we know a `ground truth'?
			\item In the Nonnegative constraint you use the diagonality argument for separability. We know this isn't true! (Let $\vec{c}(w) = (e^{w},e^{w}, e^w...)$ and $B = I$ you have a diagonal matrix but very strongly (i.e. rigidly) coupled predictors!),
			\item In Eq88, second Z should be $Z_{-t_j}$ -- you've assumed ordering again, I think?
			\item I think maybe refining 'the constraint matrix not to be defined' -- that wording sounds \textit{bad}, when what it actually means is that the points are unconstrained. Something being 'not defined' has worse connotations than 'unneeded', right?
			\item Did you want to chuck in a line about how both the BLUP and the CLUPS are improved by making the basis set use only even elements?
			\item In monotonic section you flip between using logistic and sigmoid. Choose one, stick to it.
		
		\end{enumerate}
					
		\subsection{Triviliaty in Constraints}

			Throughout the case studies, we make it fairly obvious that a number of the CLUPS predictors are \textit{trivial}, in the sense that they are elementary manipulations of the BLUP.

			Should we discuss what this means -- does this reduce the CLUPS' useability? Should we maybe split them up into a 'trivial' section (even, integrable, positive) and a non-trivial section (monotonic).

			Should we emphasise that evenness on its own being trivial doesn't necessarily matter, for example, because evenness + x might be non-trivial, so we're just providing basic building blocks?

		\subsection{Initialisation}
			I have come to realise that my initialisation stuff is not quite as general as I might like it to be -- it works for one-sided bounds, but doesn't for two sided stuff. When I've been coding it up, I have cheated a little bit - I will now attempt to formalise that cheating!

			{\it In the case where $\vec{w}$ must be optimised, we must first choose an initial starting point, $\vec{w}_0$, for the starting optimisation. The closer this is to the optimal point, the quicker the optimiser will converge.

			In order to make this efficient, we rewrite the constraint vector $\vec{c}$ in the following fashion:
			\begin{equation}
				\vec{c}(\vec{w}) = \vec{\xi} + \psi(\vec{w})
			\end{equation}
			Here $\vec{\xi}$ contains the equality constraints and $\vec{\psi}$ the inequality constraints, such that $\xi_i = 0$ if $i$ is an inequality, and $\psi_j = 0$ if $j$ is an equality\footnote{Without loss of generality, $\xi$ may also contain constant-offsets from the inequality constraints - i.e. the constraint that $Z_i > a_i$ could set $\xi_i = a_i$ and $\psi_i = \exp(w_i)$ instead of $\psi_i = a_i + \exp(w_i)$.}. By definition, $\psi(\vec{w})$ is a function $\mathbb{R}^d \to V \subset \mathbb{R}^q$, and is differentiable for all $\vec{w} \in \mathbb{R}^d$. We also limit ourselves to the case where $\psi^{-1}(\vec{v})$ exists for all $\vec{v} \in V$. We then define the \textit{buffered inverse} $\psi^{-1}_b(\vec{x})$ such that:
			\begin{equation}
				\psi^{-1}_b(\vec{x}) = \begin{cases} 
					\psi^{-1}(\vec{x}) & \vec{x} \in V
					\\
					\psi^{-1}(\vec{y}) ~~ \vec{y} \in \partial V, \text{min}(|\vec{x} - \vec{y}|) & \text{else}
				\end{cases}
			\end{equation}
			In short, the buffered inverse is equal to the inverse within $V$, and projects the vector back onto the boundary of the region when it is outside $V$. For example, the buffered inverse of the exponential function (on the Reals) would be:
			\begin{equation}
				\ln^{-1}_b(x) = \begin{cases}
					\ln(x) & x > \epsilon
					\\
					\ln(\epsilon) & \text{else{}}
				\end{cases}
			\end{equation}
			For some $0 < \epsilon \ll 1$ - chosen for numerical stability. In some parameterizations, $\psi^{-1}(\vec{x})$ is not unique (for example, $\psi_j = (\sum_i w_i)^{-1} c_j$) in such a case we simply define the buffered inverse as one such solution (the solution where $c_0 = 1$, for example).

			The algorithm for determining the initialisation point is then:
			\begin{enumerate}
				\item Compute $\{ \vec{a}^\text{BLUP} \}$ and hence $\hat{\vec{Z}}^\text{blup}$: the predictors using the normal BLUP algorithm
				\item Let $\tilde{\vec{c}} = B \vec{Z}_t = \vec{\xi} + \tilde{\vec{\varphi}}$
				\item Set $\vec{w}_0 = \psi^{-1}\left(\varphi_j\right)$
			\end{enumerate}
			}
	
	\newpage
	\section{Unimodality}

		Consider the constraint 'there is (at most) a single peak'. How might we go about expressing this idea?

		One option is to do an integer optimisation using two concatenated constraints, \verb|c_1 = Monotonic_Positive(t < T)| and \verb|c_2 = Monotonic_Negative(t >= T)|, where \verb|T| is the position of the peak - by performing the optimisation \verb|c_1 + c_2| for every value of $T \in {t_\text{predict}}$, we would find the one which minimised the global MSE of the data, and hence which was the most likely. 
		
		However, this requires bootstrapping our algorithm somewhat, and part of the appeal of our approach is that it can handle (supposedly) arbitrary constraints. 

		Instead, I propose we consider the following parameterisation of a unimodal curve:
		\begin{equation}
			f(t_i | T, \vec{w}) = \begin{cases} f_0 & i = 0 \\ f(t_{i-1}|t,T) + q(t_i,T) \exp(w_i) & \text{else}\end{cases}
		\end{equation}
			
		Where $q(t,T)$ is a function which obeys:
		\begin{equation}
			q(t,T) = \begin{cases}
				1 & t < T
				\\
				 -1 & t > T
			\end{cases}
		\end{equation}
		This is essentially a restatement of our integer optimisation algorithm. However, if we make $q$ a continuous function of $T$, then we may optimise it simultaneously with the rest of the parameters. Consider for example:
		\begin{equation}
			q(t,T) = \begin{cases}
				-1 + \frac{2}{1 + \exp\left(\frac{T - t}{\Delta}\right)}
			\end{cases}
		\end{equation} 
		Where $\Delta$ is some characteristic lengthscale -- it should probably be slightly smaller than the gap between absicssa.

		Since this isn't \textit{quite} a perfect cutoff, there is a chance that there might be some minor multimodality, but it would be significantly less than normal.

		\subsection{Positive-Unimodality}

			Constraining positivity at the same time is somewhat harder than in the pure monotone case since would we need (effectively) to constrain both endpoints to be sure. Therefore, it is easier to rewrite the constraint entirely, as:
			\begin{equation}
				f_i = \begin{cases} \exp(w_i) & i == 0
					\\
					f_{i-1} \exp(q(t_i,T) w_i^2) & \text{else}
				\end{cases}
			\end{equation} 
			This means we can't use $B = B_\text{derivative}$, and must manually compute the complex derivatives ourselves (rather than letting $B(B^TB)^{-1}$ handle it for us), but this is not in principle a difficult thing to do. I chose to use $w_i^2$ instead of $\exp(w_i)$ to enforce positivity (so that negativity can only arise from $q$) purely for numerical stability, since $\exp(\exp(w_i))$ is scary to me. The fact that $w_i^2$ has two solutions might actually help prevent suffering from node death.

	\section{Regularisation}

		Let us suppose that we want to add some form of Regularisation to our CLUPS methodology. We limit ourselves to the case where the Regularisation is imposed on $\vec{Z}$-space, i.e:

		\begin{equation}
			\mathcal{L} = \mathcal{L}_\text{clups}(\{\vec{a}\}) + R(\{\vec{a}\cdot\vec{X}\}) 
		\end{equation}		
		There are two ways to go about this:
		
		\subsection{Explicit Forcing}
			We abandon our lovely conceit of linear constraints, and let $B = I$ and $\vec{c} = \vec{p}(\vec{w})$, where $\vec{p}$ is a vector transform function which ensures that for all $\vec{w} \in \mathbb{R}^s$, $\vec{c}$ is a vector which satisfies the constraints. How this is achieved is irrelevant, other than that the function be differentiable.
			
			We therefore have that the CLUPS is:
			\begin{equation}
				\vec{a}^\text{CLUPS}_j = \vec{a}^\text{BLUP}_j - \frac{1}{D^T K^{-1} X} \left(Z^\text{blup} - \vec{p}(\vec{w})\right)_j K^{-1} \vec{D}
			\end{equation}
			We have therefore converted the Lagrangian into a function of $\vec{w}$:
			\begin{equation}
				\mathcal{L} = \left[ \sum_j \left(\text{Var}(Z_{t_j}) + \vec{a}^\text{CLUPS}_j \cdot K \vec{a}^\text{CLUPS}_j - 2 \vec{a}^\text{CLUPS}_j \cdot \vec{k}_j \right) \right] + R(p(\vec{w}))
			\end{equation}
			The terms involving $\vec{\mu}$ and $\vec{\lambda}$ have vanished since, by virtue of our reformalisation, they are equal to zero.

			As we did with inexact constraints, we may then take the derivative w.r.t $\vec{w}$:

			\begin{equation}
					\pdiv{L}{\vec{w}} = 2\left(\pdiv{\vec{p}}{\vec{w}}\right)^T \left((\vec{p} - \vec{Z}^\text{BLUPS}) - \pdiv{R}{\vec{p}} \right)
			\end{equation}
			If our Regularisation function was a smoothing kernel:
			\begin{equation}
				R(\vec{p}) = \Omega \sum_j (p_{j+1} - p_j)^2
			\end{equation}
			Then:
			\begin{equation}
				\pdiv{R}{p_i} = \begin{cases}
					2\Omega (p_0 - p_1) & i = 0
					\\
					2\Omega (2p_j - p_{j-1} - p_{j+1}) & \text{else}
				\end{cases}
			\end{equation}
		\subsection{Implicit Forcing}

			The abandoning of our lovely linearised constraints, however, feels sad. It would be nice if we could find a way to keep the modular nature. 

			If the constraint matrix $B$ is invertible, then it is possible to set:
			\begin{equation}
				\vec{p} = B^{-1} \vec{c}(\vec{w}) ~~\longleftrightarrow~~ \pdiv{\vec{p}}{\vec{c}} = {B^{-1}}^T
			\end{equation}
			Therefore:
			\begin{equation}
				\pdiv{R}{\vec{c}} = {B^{-1}}^T \pdiv{R}{\vec{p}}
			\end{equation}
			Hence we can then put this back together to find:
			\begin{equation}
				\pdiv{L}{\vec{w}} = 2\left(\pdiv{\vec{c}}{\vec{w}}\right)^T \left((BB^T)^{-1}(\vec{c} - B\vec{Z}^\text{BLUPS}) - {B^{-1}}^T\pdiv{R}{\vec{p}} \right)
		\end{equation}

		If $B$ is not invertible (or even, non-square), however, we can generally find some way to bulk it up into an invertible matrix, by introducing a number of 'unconstraining constraints' -- i.e. $B_{ij} = 1$ and $c_i = w_i$. For example, an even bulked-up constraint might look like:

		\begin{equation}
			B = \begin{pmatrix}
				1 & 0 & 0 & \hdots & 0& 0  & -1
				\\
				0 & 1 & 0 & \hdots & 0 & -1 & 0
				\\
				0 & 0 & 1 & \hdots & -1 & 0 & 0
				\\
				&&&\vdots&&&
				\\
				1 & 0 & 0 & \hdots & 0 & 0 & 0
				\\
				0 & 1 & 0 & \hdots & 0 & 0 & 0
				\\
				0 & 0 & 1 & \hdots & 0 & 0 & 0
				\\&&&\vdots&&&
			\end{pmatrix}~~~~~~\vec{c}(\vec{w}) = \begin{pmatrix}
				0
				\\
				0
				\\
				0
				\\
				\vdots
				\\
				w_1
				\\
				w_2
				\\
				w_3
				\\
				\vdots\end{pmatrix}
		\end{equation}
	\clearpage
	\renewcommand\vec[1]
	{
		\boldsymbol{\mathbf{#1}}
	}
	\section{On Predictor-Forcing}

		The key conceit which allows the BLP and all its descendants to function is the change from optimising in predictor- (or $\vec{z}-$) space to working in moment- (or $\vec{a}$-) space. This is because we do not know the behaviour of the underlying `truth' which makes it impossible to directly optimise $\vec{z}$, whilst our assumptions \textit{do} allow us to optimise against $\vec{a}$.

		This coordinate change (though necessary for the entire mathematical machinery to function) is highly inconvenient whenever you need to impose limitations on the optimisation within predictor-space. $\vec{z}$ and $\{\vec{a}\}$ are related to each other by $\hat{Z}_i = [\vec{z}]_i = \vec{a}_i \cdot \vec{X}$, by definition of the Linear Predictor. This is, however, a non-invertible relationship: knowing $\vec{a}$ guarantees knowledge of $\vec{z}$, but the inverse is not true: there are multiple different sets of $\{\vec{a}\}$ which produce a given $\vec{z}$. This is why the optimisation must be carried out within moment-space, since we cannot rewrite our cost function (the MSE) in terms of $\vec{z}$.

		The language of the CLUPS, however, provides us with a way to uniquely generate a set of $\{\vec{a}\}$ from a provided $\vec{z}$ in a very simple fashion: we simply set $B = I$ and $\vec{c} = \vec{z}$, then:
		\begin{equation}
			\vec{a}^\text{forced}_i = \vec{a}_i^\text{blup} + \frac{1}{\vec{D}\cdot K^{-1} \vec{X}} \left(z_i - \hat{Z}^\text{blup}_i \right) K^{-1} \vec{D} \label{E:Forcing}
		\end{equation}
		Taking the dot product with respect to $\vec{X}$:
		\begin{spalign}
			\hat{Z}_i^\text{forced} & = \vec{a}_i^\text{forced} \cdot \vec{X}
			\\
			& = \hat{Z}_i^\text{blup} + \frac{\vec{X} \cdot K^{-1} \vec{D}}{\vec{D} K^{-1} \vec{X}} (z_i- \hat{Z}_i^\text{blup})
			\\
			&= z_i
		\end{spalign}
		By the definition of the CLUPS as being the constraint-obeying function which lies closest to the BLUP (with the MSE as the measure of 'closeness'), it therefore follows that of all the possible sets of $\{\vec{a}\}$ which produce $\hat{Z}_j = z_j$, \eref{E:Forcing} is the one which minimises the MSE. That is, this is a unique way of inverting the Linear Predictor $\vec{a}_i = \vec{a}_i(\vec{z})$ such that the MSE is minimised.

		We term this method -- of generating a CLUPS where the constraint is that the predictor is some known value -- \textbf{predictor-forcing}. It is natural, however, to ask what the use of this is: if we already know $\vec{z}$, then surely our job is completed. After all, the entire purpose of the BL(U)P and CL(U)P was to use $\vec{a}$ to \textit{predict} $\vec{z}$.

		Predictor-forcing is a more explicit version of the technique we utilised for solving inexact constraints, in which we set $\vec{c} = \vec{c}(\vec{w})$, and hence we were able to rewrite our Lagrangian as a function only of $\vec{w}$:
		\begin{equation}
			\mathcal{L}(\vec{w}) = \sum_i \vec{a}_i(\vec{w}) \cdot K \vec{a}_i(\vec{w})- 2 \vec{k}_i \cdot\vec{a}_i(\vec{w})
		\end{equation}
		In the case of the CLUPS, $\vec{c}$ ensured that we were optimising only over the set of functions which obeyed the constraints, and since we knew that the CLUPS gave the minimal value of the MSE for each proposed value of $\vec{w}$, we could therefore guarantee that the value of $\vec{w}$ which minimised the MSE was indeed the best CLUPS which obeyed the constraints. In short, the CLUPS provided us with a way to invert $\vec{a} = \vec{a}(\vec{c}(\vec{w}))$ in a MSE-minimising fashion. 

		In a similar vein, in the case of predictor-forcing, if we let $\vec{z} = \vec{z}(\vec{w})$ then we now have a way directly propose a functional parameterisation of $\vec{z}$ which we can then optimise by writing the Lagrangian in terms of $\vec{a}_i^\text{forced}(\vec{w})$. Since we know that predictor-forcing projects into the space of MSE-minimising $\vec{a}$, we are safe in the knowledge that:
		
		\begin{equation}
			\text{min}_{\vec{w}}\left[\mathcal{L}(\vec{a}(\vec{w}))\right] = \text{min}_{\vec{a}}\left[\mathcal{L}(\vec{a})|\text{constraints of parameterisation}\right].
		\end{equation}
		
		This again might seem to defeat the point of the Linear Predictor (which is non-parametric), but we could have $\vec{z}(\vec{w}) = \vec{w}$. In this case, it is obvious from the definition of the CLUPS derivative that this reaches its optimum when $\vec{w} = \vec{\hat{Z}}^\text{BLUP}$, and that such a parameterisation is therefore utterly non-constraining.
		
		Nevertheless, our parameterisations could also serve as constraints, for example:
		\begin{equation}
			[\vec{z}(\vec{w})]_i = \frac{\mathcal{I}/\Delta x}{\sum_i^{N-1} q_i w_i} w_i ~~~~~~~~q_i = \begin{cases} 0.5 & i = 0,  N-1 \\ 1 & \text{else} \end{cases}
		\end{equation}

		This is a way of expressing '$\vec{z}$ is a function-sample which integrates to $\mathcal{I}$', but which does not impose a parametric form on the output. 
		
		{\it This was in fact my original approach to developing the CLUPS -- the benefit of the linear algebra methodology we have now developed is that, for exact constraints, it does not require optimisation, and is therefore orders of magnitude quicker to compute.}

		Predictor-forcing, therefore, is a means by which we can re-express our problem set back into $\vec{z}-$space, whilst still optimising over the statistically valid cost function `in the background'.

		The downside of this, however, is that we lose the analytical nature of the CLUPS in even the simple exact constraint cases -- we must fully optimise $\vec{z}(\vec{w})$ every time. 

		Predictor-Forcing is also distinguished (marginally) from our normal inexact constraint formalism, since it requires exact specification of the full functional form of $\vec{z}$ (and hence its derivatives), whilst the normal CLUPS machinery requires you to specify $B$ and $\vec{c}$. In some cases, the encoding is identical (positive encoding for both, for example, uses $\vec{c}_i = \vec{z}_i = \exp(w_i)$)
		
		The CLUPS machinery, however, often let us specify our constraints in much simpler ways. For example, in the case of the monotonic predictor, we used:
		\begin{align}
			B_{ij} & = \delta_{i,j-1} - \delta{ij}
			\\
			[\vec{c}(\vec{w})]_i & = \exp(w_i)
			\\
			\pdiv{\vec{c}}{\vec{w}}_{ij} & = \exp(w_i) \delta_{ij}
		\end{align}
		If we were to rewrite this in the language of predictor-forcing, however:
		\begin{align}
			z_i & = \begin{cases} w_i & i = 0
				\\
				 z_{i-1} + \exp(w_i) & \text{else}\end{cases}
			\\
			\pdiv{z_i}{w_j} & = \begin{cases}
				1 & j = 0
				\\
				\exp(w_j) & i \geq j, j > 0
				\\
				0 & \text{else}
			\end{cases}
		\end{align}
		That is, the CLUPS formalism and predictor-forcing are identical whenever there is an inexact constraint and $B = I_{m\times m}$, but otherwise the CLUPS formalism contains a lot less redundancy and, as such, there are therefore only a limited number of places where Predictor-Forcing is preferred to the normal CLUPS:

		\begin{enumerate}
			\item A complex non-linear constraint which cannot be written in the simple form $B\vec{z} = \vec{c}$ without using $B = I$.
			\item Error analysis, where proposing a new set of $\vec{z}$ and comparing the score is a necessary part of the analysis
			\item Regularisation, where the optimisation must \textit{penalise} (but not \textit{forbid}) certain configurations of $\vec{z}$.
		\end{enumerate}

		\subsection{Regularisation}

			Regularisation, when applied to a curve-fitting exercise, attempts to penalise certain outcomes in order to prevent over-fitting. A regularisation term is then added into the Lagrangian - this term is small when the model is 'well behaved', and large when it is not.
			\begin{equation}
				\mathcal{L}^\prime = \mathcal{L} + R^\text{regular}
			\end{equation}

			In a normal BLUP, the regularisation must take place in $\vec{a}-$space -- \textcolor{red}{in fact, the addition of the data-error terms into the kernel matrix is functioning as a form of regularisation by forcing the model to consider that the datapoints may not be 100\% trustworthy (JFG: I think this is true, right? It certainly \textit{looks} like a $\ell_2$ regularisation)}.

			However, if our regularisation term is being imposed due to a prior belief we have about the model (rather than a solution oriented "let's chuck in a regularisation term and hope it makes things better"), then this belief is often expressed in terms of $\vec{z}$, rather than $\vec{a}$ -- for example, a reasonable prior on a model would be \textit{the model should be smooth}, or \textit{the model should have a continuous gradient}, both of which could be expressed as:
			\begin{align}
				R_\text{smooth}(\vec{z}) &=  \Omega \sum_{i=0}^{m-1} (z_{i+1} - z_i)^2
				\\
				R_\text{curve}(\vec{z}) &=  \Lambda \sum_{i = 0}^{m-2} (z_{i+2} - 2 z_{i+1} + z_i)^2
			\end{align}
			It is clear that in the BLUP, we have no way to impose such prior knowledge (although, to be fair, unless an exceptionally strange kernel is being used, BLUPS tend to be extremely smooth by nature!), and so regularisation functions of the form $R^\text{regular}(\vec{z})$ are intractable. 

			However, if we used predictor-forcing of the form $\vec{z} = \vec{w}$ (the unconstraining-constraint, the optimum of which lies at $\vec{w} = \vec{\hat{Z}}^\text{BLUP}$), we can then formulate:
			\begin{align}
				\vec{a}_i(\vec{w}) & =  \vec{a}_i^\text{BLUP} + \frac{1}{\vec{D}\cdot K^{-1} \vec{X}} \left(w_i - \hat{Z}^\text{blup}_i \right) K^{-1} \vec{D}
				\\
				\mathcal{L}^\prime & = \sum_i \left[ \vec{a}_i(\vec{w}) \cdot K \vec{a}_i(\vec{w})- 2 \vec{k}_i \cdot\vec{a}_i(\vec{w})\right] + R(\vec{w}) 
			\end{align}
			We note that whilst the Lagrangian is unpleasant to write as an explicit function of $\vec{w}$, its derivative simplifies hugely:
			\begin{equation}
				% \pdiv{\mathcal{L}}{\vec{w}} = \left[ \pdiv{\vec{z}}{\vec{w}} \right]^T \left( 2\vec{z}(\vec{w}) - 2\vec{\hat{Z}}^\text{BLUP}+ \left.\pdiv{R}{\vec{p}}\right|_{\vec{p} = \vec{p}(\vec{w})}\right)
				\pdiv{\mathcal{L}}{\vec{w}} =  \left( 2\vec{w} - 2\vec{\hat{Z}}^\text{BLUP}+ \left.\pdiv{R}{\vec{z}}\right|_{\vec{z} = \vec{w}}\right)
			\end{equation}
		
			We can see that if $R = 0$, then the function is trivially optimised at $\vec{w}=\vec{\hat{Z}}^\text{BLUP}$, as we would expect. If $R \neq 0$, however, we can see that the position of the optimum will move, with the strength of the deviation depending on how large $R$ is.

			This therefore defines a $\vec{z}-$regularised BLUP, which we term the rBLUP.

		\subsection{Regularised CLUPS}

			We can also regularise a CLUPS. One option for doing this is directly analogous to the rBLUP, but rather than $\vec{z} = \vec{w}$, we instead set up a transform $\vec{z} = \vec{\phi}(\vec{w})$ where $\vec{\phi}$ is a function which guarantees for all $\vec{w} \in \mathbb{R}^d$ that the constraint is obeyed - it is then as simple as modifying the rBLUP identity:
			\begin{equation}
				\pdiv{\mathcal{L}}{\vec{w}} = \left[ \pdiv{\vec{\phi}}{\vec{w}} \right]^T \left( 2\vec{z}(\vec{w}) - 2\vec{\hat{Z}}^\text{BLUP}+ \left.\pdiv{R}{\vec{z}}\right|_{\vec{z} = \vec{\phi}(\vec{w})}\right)
			\end{equation}
			This, however, requires that we specify a transform, instead of using the same linear algorithm language we had already identified previously. From a computational standpoint, this is suboptimal since we would need to either:
			\begin{itemize}
				\item Abandon the linear algebra language and write everything in terms of a functional transform (and hence numerically optimise constraints for which an exact solution exists)
				\item Write every constraint twice -- once in linear algebra, and once in terms of a functional transform.
			\end{itemize}
			Luckily, there is indeed a way in which we can regularise a CLUPS using the formalism we have already created, using $B$ and $\vec{c}$. 

			We can do this trivially in the case where $B$ is a square matrix. In which case, we must assume that $\vec{c} = \vec{c}(\vec{w})$, since a square exact-constraint matrix cannot be regularised (since $m$-predictors with $m$-exact constraints are defined fully by the constraint, not by the statistical machinery of the CLUPS/BLUP).

			
			
			Our definition of 'valid constraints' requires that $BB^T$ be invertible -- therefore if $B$ is valid and square, it therefore automatically follows that $B$ is invertible. Therefore, in this case, specifying $\vec{c}$ is equivalent to specifying $\vec{z}$:
			\begin{equation}
				\vec{z} = B^{-1} \vec{c}(\vec{w})
			\end{equation}

			Therefore, the regularised-Lagrangian becomes:\def\aj{\vec{a}_j(\vec{w})}
			\begin{spalign}
				\mathcal{L} &= \left[ \sum_j \aj \cdot K \aj - 2 \vec{k}_j \cdot \aj\right] + R\left(B^{-1} \vec{c}(\vec{w})\right)
				\\
				\aj & = \vec{a}^\text{BLUP} - \frac{1}{\vec{D} \cdot K^{-1} \vec{X}} \left[B^T (BB^T)^{-1}(B \vec{\hat{Z}} - \vec{c}(\vec{w}))\right]_j K^{-1} \vec{D}
			\end{spalign}
			We can then optimise with respect to $\vec{w}$ using our existing formalism:
			\begin{spalign}
				\pdiv{\mathcal{L}}{\vec{w}} & =  \pdiv{c}{\vec{w}}^T \left[ -2(BB^T)^{-1}(B\vec{\hat{Z}} - \vec{c}(\vec{w})) + {B^{-1}}^T \pdiv{R}{\vec{z}}\right]
				\\
				& = \pdiv{c}{\vec{w}}^T {B^{-1}}^T \left[ 2 \left( B^{-1} \vec{c}(\vec{w}) - \vec{\hat{Z}} \right) + \pdiv{R}{\vec{z}} \right]
				\\
				& = \left( B^{-1} \pdiv{\vec{c}}{\vec{w}} \right)^T \left[ 2 \left( B^{-1} \vec{c}(\vec{w}) - \vec{\hat{Z}} \right) + \pdiv{R}{\vec{z}} \right]
			\end{spalign}
		

			\subsubsection{Bulking Up}
				In the case where $B$ is \textit{not} square, there does always exist a square matrix $B^\prime$ and associated vector $\vec{c}^\prime$ such that the CLUPS prediction is identical (or rather, I hope that this suffices as a proof of this).

				A valid constraint matrix $B$ (either associated with inexact or exact constraints) with size $q \times m$ constrains $q$ degrees of freedom in the predictor. This means that there are $m - q$ prediction points which are not constrained.
				
				As we have already identified, if the element $z_i$ is unconstrained, then adding in a constraint of the form $B_{ik} = \delta_{ik}$, $c_i = w_\ell$ into $B$ and $\vec{c}$ does nothing to constrain $z_i$ further -- it merely adds to the dimensionality of our computations (something we have wished to avoid up until this point).
				
				Therefore, there must be $m-q$ points for which we can add in 'unconstraining constraints', without altering the solution. Identifying which points can be (un)constrained is not necessarily trivial, and depends on the form of $B$. We propose the following algorithm for determining which prediction-points can be (un)constrained in $B^\prime$.
				\setcounter{MaxMatrixCols}{20}
				\begin{enumerate}
					\item Set up a vector of length $m$, initialised to zeros. $\vec{\gamma} = (0,0,0,0,\hdots)$
					\item Iterate through $B$ row-by-row. 
					\begin{itemize}
						
						\item For each row $[\vec{b}^{(i)}]_j = B_{ij}$, identify the right-most nonzero element for which $\gamma_j = 0$
						\begin{align*}
							\begin{matrix}
								\vec{\gamma} & = (& 0 & 0 & 0 & \hdots & 0 & \color{blue} 0 & \color{red} 1 & 0 & 0 & )
								\\
								\vec{b} & = (& 0.5 & 1 & -1 & \hdots & 0 & {\color{blue}-3} & {\color{red} 7}& 0 &0 &)
							\end{matrix}
							% \vec{c} & = (0,0,0,0,0,0,\hdots,0,{\color{blue}0},{\color{red} 1},0,0)
							% \\
							% \vec{b} & =  (0,0,1,-1,0,0.3,\hdots,0,{\color{blue}-1},{\color{red} 1},0,0)
						\end{align*}
						In this example, the $b_j = 7$ element is ignored, since the corresponding $\gamma_j = 1$ from a previous iteration.
						\item Let $k$ be the index of this element, let $\gamma_k = 1$ and move on to the next row
						\begin{align*}
							\begin{matrix}
								\vec{\gamma} & = (& 0 & 0 & 0 & \hdots & 0 & \color{blue} 1 & \color{red} 1 & 0 & 0 & )
							\end{matrix}
						\end{align*}
					\end{itemize}
					\item The vector $\vec{\gamma}$ should then have $m - q$ remaining 0 elements.
					\item We then set $\mathcal{U} \in R^{m-q\times q}$, the 'unconstraining matrix, such that $\mathcal{U}_{iq} = 1$ where $q$ is the index of the $i^\text{th}$ zero in $\vec{\gamma}$:
					\begin{align*}
						\vec{\gamma} = (0,1,1,0,1,0,0) ~~\Longrightarrow~~ \mathcal{U} = \begin{pmatrix}
							1 & 0 & 0 & 0 & 0 & 0 & 0
							\\
							0 & 0 & 0 & 1 & 0 & 0 & 0
							\\
							0 & 0 & 0 & 0 & 0 & 1 & 0
							\\
							0 & 0 & 0 & 0 & 0 & 0 & 1
						\end{pmatrix}
					\end{align*} 
					\item We can then use our normal constraint-concatenation methods: 
					\begin{align*}
						B^\prime = \begin{bmatrix}  B \\ \mathcal{U} \end{bmatrix} ~~~~~ \vec{c}^\prime \left(\begin{bmatrix}	 \vec{w} \\ \vec{w}^\prime 
						\end{bmatrix}\right) = \begin{bmatrix}	 \vec{c}(\vec{w}) \\ \vec{w}^\prime 
						\end{bmatrix}
					\end{align*}
				\end{enumerate}
				The algorithm above serves to identify which elements of the predictor set are not linearly dependent on any of the others via the constraints. Therefore, by construction, the rows of the matrix $B^\prime$ are linearly independent, and hence $B^\prime$ is square and valid, and hence invertible. We can therefore insert $B^\prime$ into the rCLUPS formalism discussed above. 
				
				This method allows us to automatically extend our linear algebra formalism without the need to specify things multiple times. 

				
				{\it Can we come up with a more convincing proof that this algorithm \textbf{always} generates a valid $B^\prime$?}
				\subsubsection{An example}

					As a worked example, consider the integral constraint on a 5-dimensional predictor:
					\begin{equation}
						B = (0.5,1,1,1,0.5)~~~c = \mathcal{I}/\Delta x
					\end{equation}
					The resulting $B^\prime$ for this is:
					\begin{equation}
						B^\prime = \begin{pmatrix}
							0.5 & 1 & 1 & 1 & 0.5
							\\
							1 & 0 & 0 & 0 & 0
							\\
							0 & 1 & 0 & 0 & 0
							\\
							0 & 0 & 1 & 0 & 0
							\\
							0 & 0 & 0 & 1 & 0
						\end{pmatrix}
						~~~~~\vec{c}^\prime(\vec{w}) = \begin{pmatrix}
							\mathcal{I}/\Delta x
							\\
							w_0
							\\
							w_1
							\\
							w_2
							\\
							w_3
						\end{pmatrix}
					\end{equation}
					The inverse of $B$ can be easily computed:
					\begin{equation}
						{B^\prime}^{-1} = \begin{pmatrix} 0 & 1 & 0 & 0 & 0
							\\
							0 & 0 & 1 & 0 & 0
							\\
							0 & 0 & 0 & 1 & 0
							\\
							0 & 0 & 0 & 0 & 1
							\\
							2 & -1 & -2 & -2 & -2\end{pmatrix} ~~~\Longleftrightarrow~~~\vec{p}(\vec{w}) = \begin{pmatrix}
								w_0
								\\
								w_1
								\\
								w_2
								\\
								w_3
								\\
								\frac{2\mathcal{I}}{\Delta x} - (w_0 + 2 w_1 + 2w_2 + 2w_3)
							\end{pmatrix}
					\end{equation}
					

	% 	Therefore, rather than writing $B = [0.5,1,1,1,1\vdots,0.5]$ for the integral constraints, we might have (With $q_j$ a suitable abscissa-weighting scheme):
	% 	\begin{equation}
	% 		[\vec{\phi}(\vec{w})]_i = \frac{\mathcal{I}}{\Delta x \sum_j q_j w_j} w_i
	% 	\end{equation}
	% 	We can use this to generate a suitable set of $\vec{a}^\text{forced}$:
	% 	\begin{equation}
	% 		\vec{a}^\text{forced}_i = \vec{a}_i^\text{blup} + \frac{1}{\vec{D}\cdot K^{-1} \vec{X}} \left(\frac{\mathcal{I}}{\Delta x \sum_j q_j w_j} w_i - \hat{Z}^\text{blup}_i \right) K^{-1} \vec{D}
	% 	\end{equation}
	% 	From which we can generate a MSE:\def\ab{\vec{a}_i^\text{blup}}\def\di{\vec{\delta}_i}
	% 	\begin{align}
	% 		\text{MSE} &= \sum_i \vec{a}^\text{forced}_i\cdot K \vec{a}^\text{forced}_i - 2\vec{k}_i \cdot \vec{a}^\text{forced}_i
	% 		\\
	% 		& = \sum_i (\ab+ \vec{\delta}_i) \cdot K (\ab+ \vec{\delta}_i) - 2 \vec{k} \cdot (\ab+ \vec{\delta}_i)
	% 		\\
	% 		&= \sum_i \text{MSE}_i + 2 \ab \cdot K \di + \di \cdot K \di - 2 \vec{k}_i \cdot \di
	% 		\\
	% 		& = \sum_i \text{MSE}_i + 2  \frac{z_i - \hat{Z}_i^\text{blup}}{\vec{D} \cdot K^{-1} \vec{X}} \ab \cdot \vec{D} + \left(\frac{z_i - \hat{Z}_i^\text{blup}}{\vec{D} \cdot K^{-1} \vec{X}}\right)^2 \vec{D} \cdot K^{-1} \vec{D} - 2 \frac{z_i - \hat{Z}_i^\text{blup}}{\vec{D} \cdot K^{-1} \vec{X}} \vec{k}_i \cdot K^{-1} \vec{D}
	% 		\\
	% 		& = \sum_i\text{MSE}_i + 2 \mathcal{F} \left(\ab - K^{-1} \vec{k} \right) \cdot \vec{D} + \mathcal{F}^2 \vec{D} \cdot K^{-1} \vec{D}
	% 		\\
	% 		\mathcal{F} &= \left(\frac{z_i - \hat{Z}_i^\text{blup}}{\vec{D} \cdot K^{-1} \vec{X}}\right)
	% 	\end{align}
	% For any proposed $\vec{z}_i$, this is the minimal MSE that can be achieved given the basis set $\Phi$ and kernel $K$. From this it is then clear that we can then directly optimise the MSE with respect to $\vec{z}_i$, or some auxiliary parameter.

	% In short, we have re-rewritten our problem \textit{back} into $\vec{z}$-space. 

	% This is key for any add??//////////itional work we might wish to do where additional limitations are placed within $\vec{z}$-space. 
\end{document}