\documentclass[]{article}
\usepackage{JML}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{dsfont}
\usepackage[left=1in,right=1in]{geometry}
\title{The CLP: Constrained Linear Predictors}
\setlength\parskip{5pt}
\setlength\parindent{0pt}
\def\llangle{\left\langle}
\def\rrangle{\right\rangle}
\newcommand\E[1]{\llangle #1 \rrangle}
\newcommand\T[1][i]{\mathcal{T}_{#1}}
\def\a{\vec{a}_t}
\def\ai{\vec{a}_{t_i}}
\def\vi{\vec{v}_i}
\def\wi{\vec{w}}
		
\begin{document}
	\maketitle

	\section*{The Goal}
		Consider a second order random process $X$, such that at each value of $t \in \mathbb{R}$, we have a random variable $X_t$. 

		We may randomly sample this vector at $n$ points, gaining a vector $\vec{T} = (t_1,t_2,t_3,\hdots)$ of times at which the samples were made, and $\vec{X} = (X_{t_i})$. Strictly speaking these are both random variables in and of themselves, up until the moment that we `realise' them. We can index into these vectors using the the integer $0 \leq i < n$, and we assume without loss of generality that the samples are sorted in time, such that $t_i < t_{i+1} \forall i$.

		In the case of the BLP, we wish to find a predictor, $\hat{X}_t$, which will predict the values of $X_t$ on a set of `prediction points', $t \in T$, subject to three further conditions:
		\begin{itemize}
			\item We are willing to present an \textit{a priori} guess at the functional form of the predictor, in the form of a `prior function' $g(t)$.
			\item The only thing we `know' (or are willing to \textit{ansatz}) about $X_t$ is the second moment kernel (a generalisation of the covariance):
			$$ \E{(X_t-g(t)) (X_s-g(s))} = k(t,s)$$
			\item Our predictor should be linear, such that:
			$$\hat{X}_t = g(t) + \vec{a}_t \cdot \left(\vec{X} - \vec{G}\right)$$
			Where $G_i = g(t_i)$
		\end{itemize}
		We again reiterate that $X_t, \vec{X}$ and $\hat{X}_t$ are - strictly speaking - random variables until we make them into real numbers at the moment we wish to actually make a prediction. $\vec{a}_t$ is a real $n$-tuple, which takes on different values at each value of $t$.

		These are the ingredients of the standard BLP. The goal of this work is to extend this by adding one further condition:
		\begin{itemize}
			\item The Predictor should obey a number of constraints of the form $h(\{X_t\}) = 0$
		\end{itemize}
		We are therefore attempting to formulate the \textit{Constrained Linear Predictor} (CLP)
	\section{Deriving the CLP}

		We define the CLP as the linear predictor which minimises the Mean Squared Error, averaged across all realisations of the random variable, computed at the set $T$ of points at which we wish to make predictions, and which obeys our constraints.

		Therefore, the CLP minimises the following Lagrangian:
		\begin{spalign}
			\mathcal{L} & = \sum_{t \in T} \langle (X_t - \hat{X}_t)^2 \rangle - \sum_j \lambda_j h_j(\{\hat{X}\}) \label{E:GlobalLagrangian}
		\end{spalign}
		Here $h_j(\{\hat{X}_t\})$ is the $j^\text{th}$ constraint on the \textit{prediction points}\footnote{For clarity and avoidance of symbol-collision with the other X-s, we will denote the prediction points as $P_i = \hat{X}_{t_i} = g(t_i) + \a \cdot \vec{X}^\prime$}, such that $h_j = 0$ when the constraint is met, and is non-zero otherwise, with the sum running over all such constraints. $\lambda_j \in \mathbb{R}$ are the associated Lagrange Multipliers. In the standard BLP we are able to treat the Lagrangian as separable in each element of $T$ - minimising the MSE individually at each $t\in T$ is equivalent to performing a global minimisation: in the CLP this is not true, and we must consider the global case.

		The issue at present is that we do not know what the behaviour of $X_t$ is -- we might have an initial guess (i.e. our prior, $g(t)$), but the entire purpose of this exercise is that we do not know $X_t$. However, by expanding out the brackets, we are able to write the Lagrangian in the following form:
		\begin{spalign}
			\mathcal{L} & = \left[\sum_{t \in T} \E{{X_t^\prime}^2} - 2\a  \cdot \E{X_t^\prime \vec{X}^\prime} + \E{(\a \cdot \vec{X}^\prime)^2} \right] - \sum_j \lambda_j h_j(\{\hat{X}\})
			\\
			& = \left[\sum_{t \in T} \E{{X_t^\prime}^2} - 2\a  \cdot \vec{k}_t + \a \cdot (K \a) \right] - \sum_j \lambda_j h_j(\{\hat{X}\})
		\end{spalign}
		Where:
		\begin{spalign}
			X_t^\prime & = X_t - g(t)
			\\
			\vec{X}^\prime & = \vec{X} - \vec{G}
			\\
			\vec{k}_t & \in \mathbb{R}^n \text{ such that } \left[ \vec{k}_t \right]_i = k(t,t_i)
			\\
			K & \in \mathbb{R}^{n\times n} \text{ such that } K_{ij} = k(t_i,t_j)
		\end{spalign}
		Note that since the kernel is, by definition, symmetric in its arguments, $K^T = K$. Note that we have also taken the explicit step of writing our kernel as a relationship between the \textit{transformed} data - i.e. $X^\prime$ - the imposition of different functions $g(t)$ might therefore warrant different kernels. This is true even if the transform is the (commonly used) constant `mean scaling', $g(t) = \E{X_t} \approx \frac{1}{n} \vec{X} \cdot \mathds{1}$.

		By performing this transform we have placed the incomputable terms - that of $\E{(X_t^\prime)^2}$ into a constant term. Since Lagrangians are invariant under constant scaling, it is possible to find an optimal value of $\a$ using only the remaining computable terms. 

		However - as we shall see - we are in the uncomfortable position of trying to impose conditions on the predicted values, $P_i = \hat{X}_{t_i} = g(t_i) + \ai \cdot \vec{X}^\prime$ whilst our object of interest is now the vector $\ai$. 

		We therefore limit ourselves to the case of \textit{linear constraints}, i.e., those which can be written in the following form:
		\begin{spalign}
			h_j(\{P\}) & = c_j - \sum_k d_{jk} P_k
			\\
			& = c_j - \sum_k d_{jk} \left( g(t_k) + \vec{a}_{t_k} \cdot \vec{X}^\prime\right) \label{E:Constraint}
		\end{spalign}
		We can then take the derivative of the Lagrangian with respect to $\ai$, and find that:
		\begin{spalign}
			\pdiv{\mathcal{L}}{\ai} & = 2 K \ai - 2 \vec{k}_i - \sum_j \lambda_j \pdiv{h_j}{\ai}
			\\
			& = 2 K \ai - 2 \vec{k}_i + \left(\sum_j \lambda_j b_{ji}\right) \vec{X}^\prime
			\\
			& = 2 K \ai - 2 \vec{k}_i + \eta_{i} \vec{X}^\prime
		\end{spalign}
		Hence, the optimal value of $\ai$ is:
		\begin{spalign}
			\ai & = K^{-1} \left( \vec{k}_i - \frac{\eta_i}{2} \vec{X}^\prime \right)
			\\
			& = \vi - \frac{\eta_i}{2} \wi
		\end{spalign}
		The optimal predicted value is:
		\begin{spalign}
			P_i & = g(t_i) + \ai \cdot \vec{X}^\prime
			\\
			& = g(t_i) + \vi \cdot \vec{X}^\prime - \frac{\eta_i}{2} \wi \cdot \vec{X}^\prime
			\\
			& = g(t_i) + A_i - \frac{\eta_i}{2} B \label{E:LagrangeOptim}
		\end{spalign}

		\subsection{Exact Constraints}

			In the case where the constraints $h_j$ are exact -- i.e. the sets $\{c\}$ and $\{d\}$ are exactly determined, we may therefore analytically solve to find the set of Lagrange multipliers, then $\vec{\eta}$, and hence compute the predictor. We note that $\vec{\eta}$ can be written as:
			\begin{equation}
				\vec{\eta} = D^T \vec{\lambda}
			\end{equation}
			Where $D_{ij} = d_{ij}$ is the constraint matrix, $\vec{\eta}_k = \eta_k$ is a vector on $\mathbb{R}^N$ and $\vec{\lambda}_k = \lambda_k$ is a vector on $\mathbb{R}^m$, where $m$ is the number of constraints. The requirement that the constraints are met can be written as:
			\begin{spalign}
				D \vec{p} = \vec{c}
			\end{spalign} 
			Where $\vec{p}_i = P_i$ is another vector on $\mathbb{R}^n$ and $\vec{c}_i = c_i \in \mathbb{R}^m$. Writing $g(t_i) + A_i = q_i$, this is then:
			\begin{spalign}
				D\left(\vec{q} - \frac{B}{2} D^T \vec{\lambda} \right) = \vec{c} \LLR \vec{\lambda} = \frac{2}{B} \left(D D^T \right)^{-1} \left( D \vec{q} - \vec{c} \right)
			\end{spalign}
			Therefore:
			\begin{spalign}
				\vec{p} =  \left( \mathds{1}_N - D^T (D D^T)^{-1} D\right)\vec{q} + D^T (DD^T)^{-1} \vec{c} \label{E:ConstrainedSolution}
			\end{spalign}
			In the case where there is only a single constraint ($m=1$), this simplifies such that $D \to \vec{d}^T$:
			\begin{spalign}
				\vec{p} = \vec{q} + \frac{c - \vec{q}\cdot \vec{d}}{\vec{d}^2} \vec{d} 
			\end{spalign}
			
		\subsection{Inexact Constraints}

			In the case where the constraints are not exact, but serve to enforce bounds -- i.e. monotonicity or positivity -- there is a problem since the parameters of the constraint are not fixed. We may not care, for example, how much greater $X_{i+1}$ is than $X_i$ is, only that it \textit{is} greater. 

			We could enforce this through slack variables and utilise the KKT conditions, however for our purposes it is better to \textit{parameterize} the constraint. 

			Various parameterizations are possible, but perhaps the most comprehensible is to consider that the \textit{prediction} points, $P_i$ are a function of some other parameters $\vec{\theta} \in R^m$, such that:
			\begin{spalign}
				P_i & = \T(\vec{\theta})
				\\
				h_j(\T(\vec{\theta})) &= 0 ~\forall~i,j, \vec{\theta}
			\end{spalign}
			For example, in the case of enforcing positivity, we might have that $P_i = e^{z_i}$, which is equivalent to asserting that $d_{ij} = \delta_{ij}$ and $c_i = e^{z_i}$. Rearranging \eref{E:LagrangeOptim}, we are able to write $\eta_i$ as a function of this Transform, and hence write $\ai$ in the following form:
			\begin{spalign}
				\ai = \vi + \frac{P_i(\vec{\theta}) - A_i - g(t_i)}{B} \wi \label{E:Reparam}
			\end{spalign}
			This might seem somewhat tautological - we have written $\ai$ in terms of the prediction values - but the entire purpose of $\ai$ is to make predictions!

			The usefulness of this comes evident when we insert \eref{E:Reparam} back into the Lagrangian -- essentially performing a change of coordinates from $\mathcal{L}(\vec{a},\vec{\theta})$ to $\mathcal{L}(\vec{\theta})$, since we have now ensured that $\a$ will always be at its optimal value for each value of $\vec{\theta}$. 
			\begin{align}
				\vec{k}_i \cdot \ai & = \vi \cdot \vec{k}_i + \frac{P_i(\vec{\theta}) - A_i - g(t_i)}{B} \wi \cdot \vec{k}_i
				\\
				\begin{split}
					~
					\\
				\ai \cdot (K\ai) & = \left(\vi + \frac{P_i(\vec{\theta}) - A_i - g(t_i)}{B} \wi  \right) \cdot\left(\vec{k}_i + \frac{P_i(\vec{\theta}) - A_i - g(t_i)}{B} \vec{X}^\prime  \right) 
				\\
				& =  \vi \cdot \vec{k}_i + \left(\frac{P_i(\vec{\theta}) - A_i - g(t_i)}{B}\right)\left(\wi \cdot \vec{k}_i + A_i\right) + \frac{\left(P_i(\vec{\theta}) - A_i - g(t_i)\right)^2}{B}
				\end{split}
			\end{align}
			Since $\vec{w} \cdot \vec{k}_i = (K^{-1} \vec{X}^\prime) \vec{k}_i = (K^{-1} \vec{k}_i) \vec{X}_\prime = \vi \cdot \vec{X}^\prime = A_i$ due to the symmetry of $K$, and the constraints are all automatically satisfied thanks to our parameterisation, we find that the Lagrangian simplifies to:
			\begin{spalign}
				\mathcal{L}(\vec{\theta}) & =  \sum_i \left( \E{(X_i^\prime)^2} -   \vec{k}_i \cdot \vi \right) + \frac{1}{B} \left(P_i(\theta) - A_i - g(t_i)\right)^2
				\\
				& =  \text{const in $\vec{\theta}$} + \frac{1}{B}\sum_i\left(P_i(\theta) - A_i - g(t_i)\right)^2
				\\
				\mathcal{L}^\prime & = \sum_i P_i\left(P_i(\theta) - 2 (A_i + g(t_i))\right)
			\end{spalign}
			Where in the final line we took the opportunity to perform a rescaling (recalling that $B > 0$ is enforced by the positive definiteness of $K$) which leaves the optimum invariant. In some cases it is trivial to identify the optimal values of $P_i$ - for example, in the case where $P_i = e^{\theta_i}$, the maximum is evidently:
			\begin{equation}
				P_i = \begin{cases} A_i + g(t_i) & \text{if this is } > 0
					\\
					0 & \text{else}
				\end{cases}
			\end{equation}
			In short, the CLP is equal to the BLP except when the condition is violated, at which point a hard cut is placed on it. 

			More complex conditions however, can lead to more complex behaviour - the monotonicity constraint, for example, exhibits the obvious behaviour that it again follows the BLP when it is monotonic, and is flat when the BLP has a negative gradient -- but the \textit{location} where the CLP becomes flat is non-trivial, with flatness necessarily occurring \textit{before} the BLP changes direction: a tradeoff in following the BLP locally versus becoming too large too early without the ability to decrease due to the monotonic constraint.

			In these cases a more complex search is required -- where the behaviour of the constraint is evident \textit{a priori} (such as the monotonic constraint), one can limit the space of the search. In the general case, however, a numerical optimisation is required. 

			The derivative of the Lagrangian with respect to the constraint parameters is:
			\begin{spalign}
				\pdiv{\mathcal{L}^\prime}{\theta_m} = 2\sum_i \left(P_i - A_i - g(t_i)\right) \pdiv{P_i}{\theta_m}
			\end{spalign}
			This can be used to numerically optimise the values of $\vec{\theta}$

		\subsection{Inexact Constraints (Redux)}
			
			We note that we performed a fairly drastic change in approach between the exact constraints and the inexact constraints -- is it possible to maintain the same approach for both?

			We consider now that the parameters $\vec{c}$ of the constraints are functions of an (unconstrained) external parameter, $\vec{z} \in \mathbb{R}^m$ - letting $\vec{c} = \text{const}$ recovers the condition of the exact equalities. However, in any  other case we must still find the values of $\vec{z}$ which optimise the global Lagrangian - and hence we need to rewrite our Lagrangian in terms of $\vec{c}$.

			From \eref{E:ConstrainedSolution}, we can rewrite the predicted value-vector (recalling that $\vec{p}_i = P_i = \hat{X}_{t_i}$) as:
			\begin{spalign}
				\vec{p} & = \vec{j} + R \vec{c}(\vec{z})
				\\
				R &= D^T (D D^T)^{-1}
				\\
				\vec{j} = \left( \mathds{1}_N - R D\right) \vec{q} &\LLR j_i  = g(t_i) + A_i + \sum_{j,k} R_{ij}D_{jk} (g(t_k) + A_k)%\left( \mathds{1}_N - D^T (D D^T)^{-1} D\right) \left(	
			\end{spalign}
			We note that from a conceptual standpoint it is not a problem for the `mixing' constraints $D_{ij}$ to be the functions of $\vec{z}$, but this assumption allows us to precompute many of the otherwise troublesome entities. We can also rewrite $\ai$ as:
			\begin{spalign}
				\ai & = \vi - \frac{\eta_i}{2} \wi
				\\
				& = \vi +  \frac{\left[R\left(\vec{c} - D \vec{q}  \right) \right] \cdot \hat{e}_i}{B} \wi
				\\
				& = \vec{j}_i + \frac{(R\vec{c})\cdot \hat{e}_i}{B} \wi
			\end{spalign}
			Where
			\begin{spalign}
				R&= D^T (D D^T)^{-1}
				\\
				\vec{j}_i & = \vi - \frac{(RD\vec{q})\cdot\hat{e}_i}{B}\wi
			\end{spalign}
			We therefore have:
			\begin{spalign}
				\vec{k}_i \cdot \ai & = \vi \cdot \vec{k}_i + \frac{A_i}{B} \left((R\vec{c}) \cdot\hat{e}_i - (RD\vec{q})\cdot \hat{e}_i\right)
				\\
				&= \text{const in $\vec{c}$} + \frac{A_i}{B} (R \vec{c})\cdot \hat{e}_i
				\\
				\ai \cdot \left(K\ai\right) & = \left(\vec{j}_i + \frac{(R\vec{c})\cdot \hat{e}_i}{B} \wi \right) \cdot  \left(K\vec{j}_i + \frac{(R\vec{c})\cdot \hat{e}_i}{B} \vec{X} \right)
				\\
				& = \text{const in $\vec{c}$} + 2\frac{(R\vec{c})\cdot \hat{e}_i}{B} \vec{j}_i \cdot \vec{X} + \frac{1}{B}((R \vec{c}) \cdot \hat{e}_i)^2
				\\
				& = \text{const in $\vec{c}$} + 2\frac{(R\vec{c})\cdot \hat{e}_i}{B}\left(A_i - (RD\vec{q})\cdot\hat{e}_i\right)  + \frac{1}{B}((R \vec{c}) \cdot \hat{e}_i)^2
			\end{spalign}
			Therefore:
			\begin{spalign}
				\mathcal{L}^\prime & = \sum_i \ai \cdot K\ai - 2 \vec{k}_i \cdot \ai 
				\\
				& = \text{const in $\vec{c}$} + \sum_i ((R \vec{c}) \cdot \hat{e}_i)^2 - 2(R\vec{c})\cdot \hat{e}_i(RD\vec{q})\cdot\hat{e}_i
				\\
				& = \text{const in $\vec{c}$} + (R \vec{c})^2 - 2 (R \vec{c})\cdot(RD\vec{q})
				\\
				& = \text{const in $\vec{c}$} + \left( R \vec{c}(\vec{z}) - RD \vec{q} \right)^2
			\end{spalign}
			The derivative with respect to the (unconstrained) vectors $\vec{z}$ is:
			\begin{spalign}
				\pdiv{\mathcal{L}^\prime}{z_m} & = \left( R \vec{c}(\vec{z}) - RD \vec{q} \right) \cdot R \pdiv{\vec{c}}{z_m}
				\\
				& = \left( \vec{p}(\vec{z}) - \vec{q} \right) \cdot R \pdiv{\vec{c}}{z_m}
			\end{spalign}
			Since $\vec{q}$ is the BLP prediction we can once again see that the derivative is zero if the BLP obeys the constraints ($\vec{c} - D \vec{q} = 0$), so the CLP will always revert to the BLP if this meets our constraints. 
		% \subsection{Mixed Constraints}

		% 	We now consider the case where some of our constraints are exact equality constraints, whilst others are inequality constraints. We denote the equality constraints as $e(\{P\})$, and the inequality constraints as $m(\{P\})$. 

		% 	The derivation proceeds exactly as before, but \eref{E:LagrangeOptim} has two terms:
		% 	\begin{spalign}
		% 		P_i &= g(t_i) + A_i - \frac{B}{2} \left( \epsilon_i + \mu_i \right)
		% 		\\
		% 		~
		% 		\\
		% 		\epsilon_i& = \sum_{j \in \text{equality}} \lambda_j b_{ji}
		% 		\\
		% 		\mu_i & = \sum_{j \in \text{inequality}} \lambda_j b_{ji}
		% 	\end{spalign}
		% 	The value of $\vec{\epsilon}$ can be determined in exactly the same way as $\vec{\eta}$ in the pure-equality case:
		% 	\begin{equation}
		% 		\vec{\epsilon} = (D_e^T D_e)^{-1} D_e^T \vec{r}_e
		% 	\end{equation}
		% 	Where $D_e$ is the constraint matrix derived from the equality subset $\{e_j\}$, and so on.
	\section{The CLUP}

		In the prior work, we assumed the the function $g(t)$ was `handed down' to us to act as a prior function. However, this may induce biases in our predictor, meaning that:
		\begin{equation}
			\E{X_t - \hat{X}_t} \neq 0
		\end{equation}
		We should ideally search for an \textit{unbiased} predictor. The derivation of the Constrained Linear Unbiased Predictor (CLUP) should follow along similar lines to the standard BLUP, but we reproduce it in full for the sake of rigour. 

		We suppose that our random variable $X_t$ can be written as:
		\begin{equation}
			X_t = m(t) + Y_t
		\end{equation}
		Where $m:R \to R$ is the `mean function' and $Y_t$ is a zero-mean random variable. Therefore:
		\begin{equation}
			\E{X_t} = m(t)
		\end{equation}
		The main difference between $m(t)$ and $g(t)$ is that we assumed $g(t)$ was just a prior to `help us along' without any intrinsic relation to $X_t$ -- here, however, we are asserting that $m(t)$ is a meaningful function -- albeit an incomputable one, since we remain unwilling to assert any properties on $\E{X_t}$. Because of this restriction, we cannot subtract away $m(t)$ from our data to formulate $\vec{X}^\prime = \vec{Y}$ -- we must keep everything in terms of our original, untransformed data.

		We \textit{can}, however, assert that $m(t)$ can be decomposed into a sum of basis functions, $\vec{\varphi}(t)$, where $\varphi_i(t): \mathbb{R} \to \mathbb{R}$ is the $i^\text{th}$ basis function. We therefore have:
		\begin{spalign}
			m(t) & = \sum_{i = 0}^\omega \phi_i(t) \beta_i
			\\
			& = \vec{\beta} \cdot \vec{\varphi}(t)
		\end{spalign}
		We again note that $\vec{\beta}$ is not a known value, however, we continue in the expectation that it will cancel out in future. We also note that without further information we must assume that $\omega \to \infty$, in practice we can limit the dimensionality by assuming that $m_\omega(t) \approx m(t)$ for finite $\omega$. We can also formulate the matrix $\Phi$:
		\begin{spalign}
			\Phi \in \mathbb{R}^{\omega\times n} \text{ such that } \Phi_{ij} = \varphi_i(t_j)
		\end{spalign}
		Therefore:
		\begin{spalign}
			\vec{X}_i = \sum_{j}^\omega \Phi_{ji} \beta_j \LLR \vec{X} = \Phi^T \vec{\beta} + \vec{Y}
		\end{spalign}
		
		
		Our linear predictor takes the form:
		\newcommand\vb{\vec{\beta}}
		\begin{spalign}
			\hat{X}_t & = \a \cdot \vec{X}
			\\
			& = \a \cdot (\Phi^T \vb) + \a \cdot \vec{Y}
			\\
			& = \vb \cdot (\Phi \a) + \a \cdot \vec{Y} \label{E:BLUP_X}
		\end{spalign}
		We can also note that:
		\begin{spalign}
			X_t - \hat{X}_t & = \left( \Phi \a - \vec{\varphi}_t \right) \cdot \vb + Y_t - \a \cdot \vec{Y}
		\end{spalign}
		Since $\E{Y} = \vec{0}$ and $\E{Y_t} = 0$ by definition, we note that the unbiased constraint is equal to:
		\begin{spalign}
			\E{X_t - \hat{X}_t} = 0 \LLR \left(\Phi\a - \vec{\varphi}_t\right) \cdot \E{\vec{\beta}} = 0
		\end{spalign}
		Therefore if we write our unbiased constraint as $\mathcal{U}_t = \E{X_t - \hat{X}_t}$, such that $\mathcal{U}_t = 0$ when the constraint is met:
		\begin{spalign}
			\mu_t \mathcal{U}_t & = \left( \mu_t \E{\vec{\beta}} \right) \cdot \left(\Phi\a - \vec{\varphi}_t\right)
			\\
			& = \tilde{\mu}_t \cdot \left(\Phi\a - \vec{\varphi}_t\right)
		\end{spalign}
		A suitable change of coordinates $\mu_t \to \tilde{\mu}_t$ therefore enables us to bypass the unknown $\E{\vec{\beta}}$. Hence the Lagrangian of the system takes the form:
		\begin{spalign}
			\mathcal{L}(\vec{a},\vec{\lambda},\{\tilde{\mu}\}) & = \sum_{t \in T} \left( \E{(X_t - \hat{X}_t)^2} + \tilde{\mu} \cdot \left(\Phi\a - \vec{\varphi}\right) \right)+ \sum_j \lambda_j h_j(\{\hat{X}\})
			\\
			& = \sum_{t \in T} \left(\E{X_t^2} + \a \cdot (K \a) - 2 \vec{k}_t \cdot \a + \tilde{\mu} \cdot \left(\Phi\a - \vec{\varphi}\right) \right)+ \sum_j \lambda_j h_j(\{\hat{X}\})
		\end{spalign}
		This is identical in form to \eref{E:LagrangeOptim}, with the addition of some additional constraints - those labelled by $\tilde{\mu}$, which act to ensure that $\E{X_t - \hat{X}_t} = 0$ for all $t\in T$, i.e. we are now including \textit{unbiasedness} as a constraint.

		We have also introduced $\vec{k}_t$ and $K$ as the second moment matrices on $X$:
		\begin{spalign}
			K \in \mathbb{R}^{n\times n} ~~~~&~~~~ K_{ij} = \E{X_{t_i} X_{t_j}}
			\\
			\vec{k}_t \in \mathbb{R}^n ~~~~&~~~~[\vec{k}_t]_i = \E{X_t X_{t_i}}
		\end{spalign}
		We once again impose the linearity condition on our constraints, such that $h_j = c_j - \sum_k d_{jk} \hat{X}_{t_k}$:
		\begin{spalign}
			\vec{h} = \vec{c} - D \vec{p}
		\end{spalign}
		Where $\vec{p}_i = \hat{X}_{t_i}$. The Lagrangian therefore simplifies to:
		\begin{spalign}
			\mathcal{L}(\vec{a},\vec{\lambda},\{\tilde{\mu}\},\vec{c})& = \sum_{t \in T} \left(\E{X_t^2} + \a \cdot (K \a) - 2 \vec{k}_t \cdot \a + \tilde{\mu} \cdot \left(\Phi\a - \vec{\varphi}_t\right) \right)+ \vec{\lambda} \cdot \left( \vec{c} - D \vec{p} \right)
		\end{spalign}
		The Lagrangian derivatives are:
		\begin{align}
			\begin{split}
			\pdiv{\mathcal{L}}{\ai} & = 2 K \ai - 2 \vec{k}_i + \Phi^T \tilde{\mu} +   \pdiv{\vec{p}}{\ai}(D^T\lambda)
			\\
			& = 2 K \ai - 2  \vec{k}_i + \Phi^T \tilde{\mu} + \left( D^T\vec{\lambda} \cdot \hat{e}_i \right) \vec{X}
			\end{split}
			\\\label{E:CLUP_Constraint}
			\pdiv{\mathcal{L}}{\vec{\lambda}} & =\vec{c} - D\vec{p}
			\\
			\pdiv{\mathcal{L}}{\tilde{\mu}} & = \Phi_t \a - \vec{\varphi}_t \label{E:CLUP_Unbiased}
		\end{align}
		Where $\hat{e}_i$ is the $i^\text{th}$ basis vector, such that $\vec{\lambda} \cdot \hat{e}_i = \lambda_i$, the $i^\text{th}$ Lagrange Multiplier \footnote{We note that we are having something of a collision with vectors associated with the $i^\text{th}$ predictor (such as $\ai$) and scalars associated with predictors or constraints which we have `stacked' into vectors - such as $\lambda_i$ and $P_i$. When indexing into labelled vectors we will attempt to make this clear - i.e. $[\ai]_j$ is the $j^\text{th}$ element of the vector associated with predictor $i$}.	The optimal value of $\a$ is therefore at:
		\def\vl{\vec{\lambda}}
		\def\ki{\vec{k}_i}
		\def\Kinv{K^{-1}}
		\def\X{\vec{X}}
		\begin{spalign}
			\ai & = K^{-1} \vec{k}_i - 2 K^{-1} \Phi^T \tilde{\mu}_i +  \left( D^T\vec{\lambda} \cdot \hat{e}_i \right)K^{-1} \vec{X}\label{E:CLUP_a}
		\end{spalign}

		\subsection{Applying Constraints}
			We now impose the unbiased constraint - substituting \eref{E:CLUP_a} into \eref{E:CLUP_Unbiased}, which gives us:
			\begin{spalign}
				\Phi \Kinv\ki - 2 \Phi K^{-1} \Phi^T \tilde{\mu}_i + \left[(D^T \vl) \cdot \hat{e}_i\right] \Phi \Kinv \X= \vec{\varphi}_i
			\end{spalign}
			Here we have again switched notation to $\vec{\varphi}_i = \vec{\varphi}_{t_i}$ for convenience. Solving for $\tilde{\mu}_i$:
			\begin{spalign}
				\tilde{\mu}_i & = \frac{1}{2} \left(\Phi K^{-1} \Phi^T\right)^{-1} \left( \Phi \Kinv\ki + \left[ (D^T \vl) \cdot \hat{e}_i\right] \Phi \Kinv \X - \vec{\varphi}_i\right)
			\end{spalign}
			Writing $M = \left(\Phi K^{-1} \Phi^T\right)$, we therefore have:
			\begin{spalign}
				\ai & = K^{-1} \Delta \ki + C \vec{\varphi}_i + \left[(D^T \vl) \cdot \hat{e}_i \right] \Kinv \Delta \X
				\\
				~
				\\
				& \text{where } C = K^{-1} \Phi^T{M}^{-1}
				\\
				& \text{and } \Delta =  \mathds{1} - \Phi^T M^{-1} \Phi K^{-1}
				\\
				&~~~~~~~~~~ = \left(\mathds{1} - C \Phi \right)^T
			\end{spalign}

			We note that $\Delta$ has the following property:
			\begin{equation}
				K^{-1} \Delta = \Delta^T K^{-1}
			\end{equation}
			We also note that:
			\begin{spalign}
				\ai^\text{clup} & = K^{-1} \Delta \ki + C \vec{\varphi}_i + \left[(D^T \vl) \cdot \hat{e}_i \right] \Kinv \Delta \X
				\\
				& = \ai^\text{blup}+ \left[(D^T \vl) \cdot \hat{e}_i \right] \Kinv \Delta \X
			\end{spalign}
			I.e., we have found that (perhaps unsurprisingly) $\ai^\text{clup}$ is equal to the BLUP case, plus a correction factor which ensures that the constraints are obeyed.

			The prediction values are therefore:
			\begin{spalign}
				\hat{X}_i = P_i & = \ai \cdot \vec{X}
				\\
				& = \ai^\text{blup}\cdot \vec{X} + (D^T \vl) \cdot \hat{e}_i \vec{X} \cdot K^{-1} \Delta \vec{X}
				\\
				& = p_i^\text{blup} + (D^T \vl) \cdot \hat{e}_i \beta
			\end{spalign}
			Where:
			\begin{spalign}
				p_i^\text{blup} & = \left(  K^{-1} \Delta \ki + C \vec{\varphi}_i \right) \cdot \X
				\\
				\beta & = \vec{X} \cdot K^{-1} \Delta \vec{X}
			\end{spalign}
			We can then form a vector of $\vec{p}_i = P_i$, such that:
			\begin{spalign}
				\vec{p}^\text{clup} & = \vec{p}^\text{blup} + \beta D^T \vl
			\end{spalign}
			
			Inserting this into the imposed constraints of \eref{E:CLUP_Constraint}, we find:
			\begin{spalign}
				D \vec{p} & = \vec{c}
				\\
				D  \vec{p}^\text{blup} + \beta D D^T \vl= \vec{c}
				\\
				\vl & = \frac{1}{\beta}\left(D D^T \right)^{-1} \left(\vec{c} - D  \vec{p}^\text{blup}\right)
			\end{spalign}

		\subsection{The CLUP}
			We can then insert this back into the definition of $\ai$ to find:
			\begin{spalign}
				\ai^\text{clup} &= \ai^\text{blup} + \frac{\left(D^T \left(D D^T \right)^{-1} \left(\vec{c} - D \vec{p}^\text{blup}\right)\right)\cdot \hat{e}_i}{\beta} K^{-1} \Delta\vec{X}\label{E:BLUP_A}
			\end{spalign}
			Where:
			\begin{spalign}
				C & = K^{-1} \Phi^T  (\Phi K^{-1} \Phi^T)^{-1}
				\\
				\Delta & = \mathds{1} - \Phi^T  (\Phi K^{-1} \Phi^T)^{-1} \Phi K^{-1}
				\\
				\beta & = \vec{X} \cdot K^{-1} \Delta \vec{X}
				\\
				\ai^\text{blp} & = K^{-1} \vec{k}_i
				\\
				\ai^\text{blup} & = \Delta^T \ai^\text{blp} + C\vec{\varphi}_i
				\\
				p_i^\text{blup} & = \ai^\text{blup} \cdot \X
			\end{spalign}
			From this it is clear to see how the CLUP, the BLUP, the CLUP and the BLP all map onto each other. In the case where we have no constraints, then $\vec{lambda} = 0$, and $\ai^\text{clup} = \ai^\text{blup}$, and in the case where we do not perform any simultaneous fitting, $C = 0$ and $\Delta = \mathds{1}$, so $\ai^\text{blup} = \ai^\text{blp}$.

			
		\subsection{Optimising the CLUP}
			
			However, as before with the CLP, we have a problem if some of our constraints were inexact - that is, $\vec{c} = \vec{c}(\vec{z})$. We reiterate that this arises because, in our formalism, and inequality takes the following form:
			\begin{equation}
				\text{Constraint $i$: } a \geq b \LLR a - b = \underbrace{e^z}_{c_i}
			\end{equation}
			In the case where it is unknown \textit{how much bigger} $a$ is than $b$, we must find the value of $c_i$ which minimises the Lagrangian. In short, we have formulated a way to write $\ai$ as an exact-constraint-obeying function of some unknown parameters $\vec{z}$ -- we must now optimise with respect to these parameters. 

			Therefore:
			\begin{spalign}
				\pdiv{\mathcal{L}}{z_k} & = \sum_{i} \pdiv{\mathcal{L}}{\ai} \cdot \pdiv{\ai}{z_k}
				\\
				& =  \sum_{i} \pdiv{\mathcal{L}}{\ai} \cdot \left(\pdiv{\ai}{\vec{c}} \pdiv{\vec{c}}{z_k}\right)
				\\
				& = 2  \sum_{i} \left( K \ai - \ki \right) \cdot \left(\pdiv{\ai}{\vec{c}} \pdiv{\vec{c}}{z_k}\right)
			\end{spalign}
			In order to compute $\pdiv{\ai}{\vec{c}}$ it is convenient to use outer products to write it in the following form:
			\begin{equation}
				\ai = \ai^\text{blup} + \left( (K^{-1} \Delta \vec{X}) \otimes \hat{e}_i \right) \left(D^T (DD^T)^{-1} (\vec{c} - D \vec{\alpha})\right)
			\end{equation}
			Hence:
			\begin{equation}
				\pdiv{\ai}{\vec{c}} = \left( (K^{-1} \Delta \vec{X}) \otimes \hat{e}_i \right)D^T (DD^T)^{-1}
			\end{equation}
			Recalling that $(\vec{u} \otimes \vec{w})^T = \vec{w} \otimes \vec{u}$, therefore we have:
			\begin{spalign}
				\pdiv{\mathcal{L}}{z_k} & =2  \sum_{i} \left( (K^{-1} \Delta \vec{X}) \otimes \hat{e}_i\right)\left( K \ai - \ki \right) \cdot D^T (DD^T)^{-1}\pdiv{\vec{c}}{z_k}
			\end{spalign}
			Exploiting the inner product once again:
			\begin{spalign}
				\pdiv{\mathcal{L}}{z_k} & =2  \left(\sum_{i} \Delta^T \left[ (\ai - K^{-1} \ki ) \cdot \vec{\X} \right] \hat{e}_i \right)\cdot D^T (DD^T)^{-1}\pdiv{\vec{c}}{z_k}
			\end{spalign}
			Recall that:
			\begin{spalign}
				\Delta^T \ai  & = (1 - C \Phi) \ai
				\\
				& = \ai - C \vec{\varphi}_i
			\end{spalign}
			This follows from the fact that $\ai$ must obey the unbiasedness constraint. Expanding the definition of $\ai$ and $\ai^\text{blup}$:
			\begin{spalign}
				\Delta^T \ai  & = \left(\ai^\text{blup} + \frac{s_i}{\beta} K^{-1} \Delta \X \right) - C \vec{\varphi}_i
				\\
				& = \left(\Delta^T K^{-1} \ki + C \vec{\varphi}_i+ \frac{s_i}{\beta} K^{-1} \Delta \X \right) - C \vec{\varphi}_i
				\\
				& = \Delta^T K^{-1} \ki + \frac{s_i}{\beta} K^{-1} \Delta \X
			\end{spalign}
			Where:
			\begin{equation}
				\vec{s} = \left(D^T \left(D D^T \right)^{-1} \left(\vec{c} - D \vec{p}^\text{blup}\right)\right) \LLR s_i = \vec{s} \cdot \hat{e}_i
			\end{equation}
			Therefore:
			\begin{spalign}
				\vec{X} \cdot \left(\Delta^T \ai - \Delta^T K^{-1} \ki \right) & = \vec{X} \cdot \left( \Delta^T K^{-1} \ki + \frac{s_i}{\beta} K^{-1} \Delta \X - \Delta^T K^{-1} \ki \right)
				\\
				& = \frac{s_i}{\beta} \vec{X} \cdot K^{-1} \Delta \vec{X}
				\\
				& = s_i
			\end{spalign}
			Therefore:
			\begin{equation}
				\pdiv{\mathcal{L}}{z_k} =2 \left[(DD^T)^{-1} \left(\vec{c} - D \vec{p}^\text{blup}\right) \right] \cdot \pdiv{\vec{c}}{z_k}
			\end{equation}
			In the case where $c_k = c_k(z_k)$, i.e. each constraint is associated with only one parameter, this simplifies to:
			\begin{equation}
				\pdiv{\mathcal{L}}{\vec{z}} =2 \left[(DD^T)^{-1} \left(\vec{c} - D \vec{p}^\text{blup}\right) \right] \odot \vec{\delta}(\vec{c}) \label{E:CLUP_GRAD}
			\end{equation}
			Where $\odot$ is the elementwise Hadamard product and:
			\begin{equation}
				[\vec{\delta}(\vec{c})]_i = \pdiv{c_i}{z_i}
			\end{equation}
			For example, in the case where $\vec{c} = e^{z_i}$, we find that $\vec{\delta} = \vec{c}$.
		
			\subsubsection{Sanity Check: Recovering the BLUP}

				We have already seen that the CLUP is a constrained version of the BLUP, so it should be trivially obvious that when the BLUP meets the constraints, then the CLUP coincides with the BLUP. 

				However, as a validation of our method, we note that the condition that the BLUP meets the constraints is exactly $D \vec{p}^\text{blup} = \vec{c}$, at which point \eref{E:CLUP_GRAD} is trivially zero, since the left hand side of the dot product is the zero vector -- hence the BLUP is an extremum of our Lagrangian in the case where it meets the constraints. 

				
	\subsection{The CL(U)P in Action}

		\begin{figure}[t]
			\includegraphics[width=\linewidth,keepaspectratio=true]{Figs/CLUP_comparison.png}
			\caption{\it A series of predictions on a dataset of $N=10$ points drawn from the dotted black curve with Gaussian noise ($\sigma=2$) added on. The models are described in detail in the text. The kernel has is a squared exponential with length-scale $\ell_0 = 1$ throughout. $\epsilon$ is the RMS deviation from the true, underlying function -- this is distinct from the MSE, which is a function of the data.}\label{F:CLUP}
		\end{figure}

		

		In Figure \ref{F:CLUP}, we show the relative performance of the constrained predictors when fitting a bi-sigmoid function with Gaussian noise generated. We impose the constraint that we know the underlying function is \textbf{monotonic}.
		
		The monotonicity constraint means that we should always have $P_{i} \geq P_{i-1}$, assuming the prediction points are suitably time-ordered - our inexact constraint therefore takes the form:
		\begin{spalign}
			\vec{c}(\vec{z}) \in \mathbb{R}^{n-1}~~~&~~~ 	[\vec{c}(\vec{z})]_i = e^{z_i}
			\\
			D \in \mathbb{R}^{(n-1)\times n} ~~~&~~~ D_{ij}  = -\delta_{ij}+ \delta_{(i+1)j}\label{E:CLP_Monotone}
		\end{spalign}

		To our generated dataset, we fitted the following models:
		\begin{itemize}
			\item \textbf{BLP}: A standard BLP using the simple $\vec{X} \cdot K^{-1} \vec{k}$ predictor. We did not perform a mean-scaling on this predictor: $g(t) = 0$.
			\item \textbf{CLP}: As with the BLP, but with the addition of the monotonic constraint (see \eref{E:CLP_Monotone})
			\item \textbf{BLP\_Mean}/\textbf{CLP\_Mean}: As above, but the prior is set to $g(t) = \frac{1}{N} \mathds{1} \cdot \vec{X}$, i.e. the sample mean.
			\item  \textbf{BLP\_LinearPrior}/\textbf{CLP\_LinearPrior}: The prior is set to $g(t) = mt + c$, the straight line joining the two extreme datapoints in the sample. To avoid bootstrapping, these datapoints are then removed from the training dataset, so the fit is performed on $N-2$ datapoints.
			\item $n$-\textbf{BLUP} the standard BLUP, with $\Phi$ expanded to $n^\text{th}$ order. 
			\item $n$-\textbf{CLUP}, as with the $n$-\textbf{BLUP}, but with the addition of the monotonic constraint.
		\end{itemize}

		We note that we deliberately offset and up-scaled the bi-sigmoid to highlight the difficulty faced by the BLP/CLP without the use of a prior function.

		We see this reflected in Fig. \ref{F:CLUP}: the BLP and CLP demonstrate extremely poor fits to the data; with the BLP oscillating down to 0 in the gaps between datapoints. The CLP tries to strike a balance between the BLP fit and remaining monotonic - the result is an underwhelming fit which goes nowhere near the data. 
		
		The addition of a prior $g(t)$ shows a significant improvement in the fit -- the simple mean shift prevents the reversion down to 0, but i.e. at $t \approx -5$ results in a similar deviation upwards. The more complex LinearPrior models show a much better fit - the deviation at $t \approx -5$ is much smaller, and similar improvements are observed at $t \approx3,+7$. This is noteworthy as the model has only 8 points to infer from, and yet shows a better fit than the BLP/CLP\_Mean models which have more data to work from.
		
		The BLUP/CLUP models again show an improvement - the 1-BLUP/1-CLUP models are directly comparable to the LinearPrior models since they both attempt to set a linear function, but the LinearPrior use only the extremum points, and must then remove those datapoints to prevent over-fitting: the 1-BLUP and 1-CLUP, however, simultaneously fit the linear fit and the predictor, which gives an improved fit. 

		Finally, the 5-BLUP/5-CLUP models fit a $5^\text{th}$ order polynomial, and demonstrate a significant improvement in the fit -- the model is able to accurately anticipate that the line should be flat at $t\approx-5$.

		We also note that, as measured by the true-RMS ($\epsilon$ in the figure), the inclusion of the monotonic constraint always improved the quality of the prediction -- even the 5-BLUP which provided a good fit was bested by the 5-CLUP, by a non-trivial margin. 

		These conclusions are maintained even as we increase the number of datapoints (as seen in Fig. \ref{F:CLUP2}) -- the margins become notably smaller, which is unsurprising as the predictor will tend towards becoming monotonic even without the inclusion of the constraints, the the CLP/CLUP generally outperform the BLP/BLP even when the amount of data becomes very large - as in Fig. \ref{F:CLUP3}
		\begin{figure}[t]
			\includegraphics[width=\linewidth,keepaspectratio=true]{Figs/CLUP_comparison_moreData.png}
			\caption{\it As with \ref{F:CLUP}, but with $N=40$ datapoints ($N=38$ for the `Prior' models)}\label{F:CLUP2}
		\end{figure}
		\begin{figure}[t]
			\includegraphics[width=\linewidth,keepaspectratio=true]{Figs/CLUP_comparison_moremoreData.png}
			\caption{\it As with \ref{F:CLUP}, but with $N=520$ datapoints ($N=518$ for the `Prior' models)}\label{F:CLUP3}
		\end{figure}

	
	\section{Optimising the Kernel}

		\subsection{Leave-One-Out}

			We note that `leaving a datapoint out' of the analysis is equivalent to the case where the error in the chosen datapoint is increased to an infinite degree of uncertainty. We can therefore write:
			\begin{align}
				K_{ij}^{(m)}(\mu) = \begin{cases}
					K_{ii} + \mu^2 & \text{if } {i = j = m}
					\\
					K_{ij} & \text{else}
				\end{cases} \LLR K^{(m)} = K + \mu^2 R_m
			\end{align}
			The inverse of this matrix can be computed as:
			\begin{equation}
				(K_{ij}^{(m)})^{-1} = \left( \mathds{1} + \mu^2K^{-1} R_m\right)^{-1} K^{-1}
			\end{equation}
			The product $\mathds{1} + K^{-1} R_m$ can be computed easily:
			\begin{spalign}
				(\mathds{1} + K^{-1} R_m)^{-1} & = \begin{pmatrix}
					1 & 0 & \hdots & 0 & \mu^2 K^{-1}_{0m} & 0 & \hdots & 0
					\\
					0 & 1 & \hdots & 0 & \mu^2 K^{-1}_{1m} & 0 & \hdots & 0
					\\
					\vdots
					\\
					0 & 0 & \hdots & 0 & 1+\mu^2 K^{-1}_{mm} & 0 & \hdots & 0
					\\
					\vdots
					\\
					0 & 0 & \hdots & 0 & \mu^2 K^{-1}_{nm} & 0 & \hdots & 1
				\end{pmatrix}^{-1}
				\\
				& = \begin{pmatrix}
					1 & 0 & \hdots & 0 & -\frac{\mu^2 K^{-1}_{0m}}{1+\mu^2 K^{-1}_{mm}} & 0 & \hdots & 0
					\\
					0 & 1 & \hdots & 0 & -\frac{\mu^2 K^{-1}_{1m}}{1+\mu^2 K^{-1}_{mm}} & 0 & \hdots & 0
					\\
					\vdots
					\\
					0 & 0 & \hdots & 0 & \frac{1}{1+\mu^2 K^{-1}_{mm}} & 0 & \hdots & 0
					\\
					\vdots
					\\
					0 & 0 & \hdots & 0 & -\frac{\mu^2 K^{-1}_{nm}}{1+\mu^2 K^{-1}_{mm}} & 0 & \hdots & 1
				\end{pmatrix}
			\end{spalign}
			In the limit that $\mu \to \infty$ (assuming that $K^{-1}_{mm} \neq 0$)
			\begin{spalign}
				(\mathds{1} + K^{-1} R_m)^{-1} & =  \begin{pmatrix}
					1 & 0 & \hdots & 0 & -\frac{K^{-1}_{0m}}{K^{-1}_{mm}} & 0 & \hdots & 0
					\\
					0 & 1 & \hdots & 0 & -\frac{K^{-1}_{1m}}{ K^{-1}_{mm}} & 0 & \hdots & 0
					\\
					\vdots
					\\
					0 & 0 & \hdots & 0 & 0 & 0 & \hdots & 0
					\\
					\vdots
					\\
					0 & 0 & \hdots & 0 & -\frac{K^{-1}_{nm}}{K^{-1}_{mm}} & 0 & \hdots & 1
				\end{pmatrix}
				\\
				& = S(m)
			\end{spalign}
			Hence:
			\begin{spalign}
				J(m)^{-1} & = \lim_{\mu \to \infty} \left(K^{(m)}(\mu)\right)^{-1}
				\\
				& = S(m) K^{-1} 
			\end{spalign}
			Hence the modified $\text{a}_\text{blp}$ is:
			\begin{spalign}
				{\a}^\text{blp}(m) = S(m) {\a}^\text{blp}
			\end{spalign}
			And the validation predictor is:
			\begin{spalign}
				\hat{X}(t,m) = {\a}^\text{blp} \cdot S^T(m) \vec{X}
			\end{spalign}
			If we write 



	


		% \subsection{Gaussian-Style Errors}

		% 	In this attempt, we try to derive the errors in the standard Bayesian-analysis way (c.f. Sivia, etc.).

		% 	When we formulated our Lagrangian, \eref{E:GlobalLagrangian}, we note that we were performing the usual trick of optimising the \textit{logarithm} of the Lagrangian we were actually interested in:
		% 	\begin{equation}
		% 		L(\vec{\theta}) = e^{-\mathcal{L}(\vec{\theta})}
		% 	\end{equation}
		% 	By minimising $\mathcal{L}$, we were therefore maximising $L$. If we assume that -- even if it is non-Gaussian -- the structure of $\mathcal{L}$ is such that it is tightly peaked around the optimal value, we may approximate the behaviour around the peak by the second order Taylor expansion:
		% 	\begin{equation}
		% 		\mathcal{L} \approx \mathcal{L}_\text{opt} + \frac{1}{2}\vec{\theta}^T H \vec{\theta} \LLR L(\vec{\theta}) = L_0 e^{-\frac{1}{2}\vec{\theta}^T H \vec{\theta}}
		% 	\end{equation}
		% 	Where $H$ is the usual Hessian matrix:
		% 	\begin{equation}
		% 		H = \left. \pdiv{^2 \mathcal{L}}{\vec{\theta}^2} \right|_{\theta = \theta_\text{opt}}
		% 	\end{equation}
		% 	By comparison with a simple Gaussian, the 1-sigma error estimate is then:
		% 	\begin{equation}
		% 		\sigma_i = \frac{1}{\sqrt{H^{-1}_{ii}}}
		% 	\end{equation}
		% 	The error on the optimised value $\ai$ is therefore:
		% 	\begin{spalign}
		% 		\pdiv{^2\mathcal{L}}{\ai \partial \vec{a}_j} = K \delta_{ij} \LLR \sigma_{[\ai]_j} = \frac{1}{\sqrt{K^{-1}_{jj}}}
		% 	\end{spalign}
		% 	Therefore if we write $[\vec{\sigma}]_j = \frac{1}{\sqrt{K^{-1}_{jj}}}$, we have:
		% 	\begin{equation}
		% 		\ai = \ai^{\text{clup}} \pm \vec{\sigma}
		% 	\end{equation}
		% 	Hence:
		% 	\begin{spalign}
		% 		\hat{X}_i = \ai^{\text{clup}}\cdot \vec{X} \pm \vec{\sigma} \cdot \vec{X}
		% 	\end{spalign}
		% 	Notably, this is independent of $i$, which means that the error is constant across all points - we don't, for example, predict small errors when predicting a point close to one of our  observed sample points.




			\newpage
		\section{Initialisation}

			In the case where $\vec{w}$ must be optimised, we must first choose an initial starting point, $\vec{w}_0$, for the starting optimisation. The closer this is to the optimal point, the quicker the optimiser will converge.

			In order to make this efficient, we rewrite the constraint vector $\vec{c}$ in the following fashion:
			\begin{equation}
				\vec{c}(\vec{w}) = \vec{\xi} + \psi(\vec{w})
			\end{equation}
			Here $\vec{\xi}$ contains both the equality constraints and any constant-offsets associated with the inequality constraints, such that we may then enforce the following conditions on $\vec{\psi}$:
			\begin{equation}
				\left[ \vec{\psi}(\vec{w}) \right]_i  \begin{cases}
						= 0 & \text{if $i$ exact constraint}
						\\
						\geq 0 & \text{else}
					\end{cases}
			\end{equation}
			For example, if condition $j$ is that $x_j \geq -4$, then $\xi_j = -4$ and $\psi_j = \exp(w_j)$. We also limit ourselves to the case where $\vec{w} = \psi^{-1}(\vec{c} - \vec{\xi})$ exists. Note that this is not a limitation on our general method, but rather a choice made for efficient initialisation.

			The algorithm for determining the initialisation point is then:
			\begin{enumerate}
				\item Compute $\{ \vec{a}^\text{BLUP} \}$ and hence $\hat{\vec{Z}}^\text{blup}$: the predictors using the normal BLUP algorithm
				\item Let $\tilde{\vec{c}} = B \vec{p}_t = \vec{\xi} + \tilde{\vec{\varphi}}$
				\item Project onto the constraint-meeting surface:
				$$ \varphi_j = \begin{cases} \tilde{\varphi}_j & \text{if } \tilde{\varphi}_j \geq 0
					\\
					0 & \text{else} \end{cases}$$
				\item Set $\vec{w}_0 = \psi^{-1}\left(\varphi_j\right)$
			\end{enumerate}
			In practice, a small amount of numerical tolerance might be required (setting a $\varphi_j =0$ when $\psi^{-1} = \ln(\varphi)$ is not numerically stable), so at step 3 we suggest setting $\varphi_j = \epsilon$, some very small numerical quantity.

			\subsection{Comments on Initialisation}

				This method of initialisation is a na\"ive projection from the BLUP onto the space of constraint-obeying functions. In some simple cases, this projection is in fact equal to the global maximum: the case of positive functions, for example - the na\"ive projection truncates the BLUP to be equal to 0 wherever the BLUP would become negative, which is exactly the global solution. 
				
				In some pathological cases, however, this projection might lead to a function extremely far away from both the global maximum and the BLUP: consider the case of a BSCLUP constrained to be monotonically increasing, but where the BLUP is monotonically \textit{decreasing}. In this case, the projection of $\vec{w}_0$ would result in a flat line at the height of $Z^{BLUP}_0$ -- a rather significant deviation, and unlikely to be close to the optimum.

				Experimentally, we find that this initialisation serves as a good initial \textit{ansatz} as to the location of the optimum point for most real-world applications.
				
				
			% \begin{spalign}
			% 	\vec{a}_{t_i}^\text{blup}(\vec{p}_\text{blup}) & = K^{-1} \Delta \ki + C \vec{\varphi}_i + \frac{\vec{p}^\text{blup} \cdot \hat{e}_i-  \vec{X} \cdot K^{-1} \Delta \ki - \vec{X} \cdot  C \vec{\varphi}_i }{\vec{X} \cdot K^{-1} \Delta \vec{X}} K^{-1} \Delta \vec{X}
			% 	\\
			% 	\ai^\text{clup}(\vec{p}_\text{blup},\vec{z})  & = \vec{a}_{t_i}^\text{blup}(\vec{p}_\text{blup}) + \frac{\left(D^T \left(D D^T \right)^{-1} \left(\vec{c}(\vec{z}) - D \vec{p}^\text{blup}\right)\right)\cdot \hat{e}_i}{\vec{X} \cdot K^{-1} \Delta\vec{X}} K^{-1} \Delta\vec{X}
			% \end{spalign}
			% Given MCMC is computationally intensive, it behoves us to note where components can be precomputed:
			% \begin{spalign}
			% 	\vec{a}_{t_i}^\text{blup}(\vec{p}_\text{blup}) & = \underbrace{\left( K^{-1} \Delta \ki + C \vec{\varphi}_i - \frac{\vec{X} \cdot K^{-1} \Delta \ki - \vec{X} \cdot  C \vec{\varphi}_i }{\vec{X} \cdot K^{-1} \Delta \vec{X}} K^{-1} \Delta \vec{X} \right)}_{\vec{\gamma}_i}+ \vec{p}^\text{blup}\cdot \hat{e}_i\underbrace{\left(\frac{1}{\vec{X} \cdot K^{-1} \Delta \vec{X}} K^{-1} \Delta \vec{X} \right)}_{\vec{\epsilon}}
			% 	\\
			% 	& = \vec{\gamma}_i + {p}^\text{blup}\cdot \hat{e}_i \vec{\epsilon}
			% \end{spalign}
			% Therefore:
			% \begin{spalign}
			% 	\ai^\text{clup} & = \vec{\gamma}_i +f_i \vec{\epsilon}
			% 	\\
			% 	f_i & =  \left( H \vec{c}(\vec{z}) + G \vec{p}^\text{blup} \right) \cdot \vec{e}_i
			% 	\\
			% 	H & = D^T (DD^T)^{-1}
			% 	\\
			% 	G & = \mathds{1} - D^T(DD^T)^{-1} D
			% \end{spalign}
			% Note that whilst $H$ is the pseudo-inverse of $D$, this only holds with left-multiplication (i.e. $D H = \mathds{1}$), but in general it is not true that $HD = \mathds{1}$, and so $G \neq 0$ - though in some cases this might be true (i.e. in the positive-constraint case, in which $D = \mathds{1}$).
			
			% The Global Lagrangian (given that the constraints are automatically met) is then:
			% \begin{spalign}
			% 	\mathcal{L} & = \sum_i \ai \cdot K \ai - 2 \ki \cdot \ai
			% 	\\
			% 	& =\text{const} +  \sum_i \left( \vec{\gamma}_i + f_i \vec{\epsilon} \right) \cdot K \left(\gamma_i + f_i \vec{\epsilon} \right) - 2 \ki \cdot (\vec{\gamma}_i + f_i \vec{\epsilon})
			% 	\\
			% 	& = \text{const} + \sum_i 2 f_i \vec{\gamma}_i K \vec{\epsilon} + f_i^2 \vec{\epsilon} K \vec{\epsilon} - 2 f_i \ki \cdot \vec{\epsilon}
			% \end{spalign}
			% We can rewrite this as:
			% \begin{spalign}
			% 	\mathcal{L}^\prime & = \mathfrak{e} \vec{f}^2 + 2 \vec{f} \cdot \vec{\mathfrak{g}}
			% 	\\
			% 	\vec{f} & =  H \vec{c}(\vec{z}) + G \vec{p}^\text{blup}
			% 	\\
			% 	\mathfrak{e} & = \vec{\epsilon} \cdot K \vec{\epsilon}
			% 	\\
			% 	[\vec{\mathfrak{g}}]_i & = \left(K \gamma_i   - \vec{k}_i \right)\cdot \vec{\epsilon}
			% \end{spalign}
			% All these components -- aside from $\vec{f}$ -- can be precomputed, and so the MCMC routine requires only 2 matrix products, 2 dot products and however much computation is required to compute $\vec{c}(\vec{z})$ -- this is a significant improvement over the naive method. 

		
			\newpage
			\section{Prediction Errors}
		
				\subsection{Why the BLUP Approach doesn't work}
					
					The approach in standard BLUP texts is to simply use that the prediction error is (approximately -- some assumptions needed if I recall?) equal to the MSE evaluated at the optimum.
		
					This, however, utilises the assumption that each of the prediction points is independent; an assumption that does not follow through with the BSCLUP. We have emphasised that the BSCLUP prediction is on the \textit{entire} sequence/series of points - and hence any associated error must be computed on a global scale. 
		
					Simply put, it does not make sense to think about the error associated with just one point, when moving that point might have an impact on subsequent points (i.e., it is \textit{impossible} to move a point upwards in a monotonic predictor-series if the subsequent point already has the same prediction value, as this would violate the constraint.) 
					
					This concern is not merely limited to the predictor-sequences, as predictor-series also violate the assumptions that allow the MSE to be used; a trivial example would be the error on a predictor-series constrained to be non-negative, but which is predicted to be equal to zero. It is evident that a symmetric error around $Z = 0$ would not be representative of the predictor error at that point.
					
					We must therefore lend slightly more care and attention to our errors.
					
				\subsection{The MCMC Approach}
		
					Errors on sequences naturally lend themselves to an MCMC-style approach, as this provides a natural way to explore the intercorrelation between the sequence/series.
		
					In an ideal scenario, we would simply vary the predictor values, $\{\hat{Z}_\text{clup}\}$, and use this to generate a score $\mathcal{L}$ which the MCMC engine could explore. This faces two major problems:
					\begin{enumerate}
						\item The score function $\mathcal{L}$ is expressed in terms of $\{{\vec{a}}\}$, but $\hat{Z}$ and $\vec{a}$ are related through a non-invertible dot-product.
						\item With complex constraints, the majority of proposed variations to $\hat{Z}$ would be invalid, and hence the MCMC engine would not be able to produce a reliable chain.
					\end{enumerate}
		
					We must therefore run the MCMC engine in $\vec{a}$-space; which has the unfortunate by-product of being much higher-dimensional, and therefore has a higher autocorrelation length. However, blindly proposing a new $\vec{a}$ falls afoul of point 2) raised above, namely that the majority of the time, the resulting predictions will not be valid. 
		

					I therefore propose 4 potential algorithms for generating a valid MCMC chain.

					\subsubsection*{Algorithm 1: ``Fuck You, Markov, You Don't Know Me''}
						
						This algorithm is simple: any proposed $\{\vec{a}\}$ which violate the constraints is given a score of $-\infty$, and the rest is left up to the MCMC engine to handle. 

						This \textit{might} work in some of the inequality cases -- it almost certainly won't work in exact constraints (i.e. the probability of the MCMC generating a curve with an integral equal to 1 (within machine precision) is vanishingly small).

						I do not recommend this, but it is technically an option.

					\subsubsection*{Algorithm 2: ``Exactitude''}

						In this case, we treat the variation as happening on the space of $\{a_\text{nqblup} \}$ (nqBLUP = not-quite-best LUP, since we have varied it away from the optimum!). If the constraints were exact, then this is almost identical to simply varying the $\{\vec{a}\}$, you simply have to correct the predictor using the BSCLUP identity. If the constraints are inexact, then for each proposed $\{ a_\text{nqblup}\}$ we compute the exact value of $\vec{c}$ which optimises the predictor; we then have a means of associating a variational score to a predictor which is away from the mean, but which is guaranteed to obey the correct behaviour. 

						This is probably the most theoretically justifiable algorithm; the variables within $\vec{w}$ were always a fiction and so 'optimising them away' to produce the 'optimised-variation' seems like the best approach. 

						The downside is that -- aside from exact constraints and certain trivial cases -- this is computationally very costly, and will take a vast amount of computing power to produce meaningful results.
						
					\subsubsection*{Algorithm 3: ``Dual Variation''}

						It is clear that the MCMC must vary $\vec{a}_\text{nqblup}$ in order to produce meaningful results - however, we might take objection to the optimisation of $\vec{w}$ which the ``Exactitude'' method - firstly on practical grounds, and secondly on the idea that we are explicitly varying \textit{away} from the optimum -- so why do we not also vary $\vec{w}$\footnote{I don't know if I believe this, but would be interested in some thoughts!}?

						In this case, we form a composite vector $\{\vec{a}_\text{nqblup}, \vec{w}\}$ such that for each variation we can construct a $\vec{c}$, and then through the BSCLUP identity a $\vec{a}_\text{nqBSCLUP}$ and hence a score.

						The downside of this is that:
						\begin{itemize}
							\item We might argue the opposite way and say that unoptimised $\vec{w}$ values are meaningless
							\item This increases the number of dimensions (potentially up to twice as many), and so increases the autocorrelation time.
						\end{itemize}

					\subsubsection*{Algorithm 4: `Eh, Close Enough'}

						This final algorithm works similarly to Algorithm 2, except that no direct optimisation is involved. After proposing a new $\{\vec{a_\text{nqblup}}\}$, you then perform the Initialisation Projection:

						\begin{enumerate}
							\item Compute $\vec{\hat{\vec{Z}}}^\text{nqblup}$ using the normal BLUP algorithm
							\item Let $\tilde{\vec{c}} = B \vec{\hat{\vec{Z}}}^\text{nqblup} = \vec{\xi} + \tilde{{\varphi}}(\vec{w})$
							\item Project onto the constraint-meeting surface:
							$$ \varphi_j = \begin{cases} \tilde{\varphi}_j & \text{if } \tilde{\varphi}_j \geq 0
								\\
								0 & \text{else} \end{cases}$$
							\item Then set $\vec{c}^\prime = \vec{\xi} + \vec{\varphi}$
							\item Use $\{\vec{a}_\text{nqblup}\}$ and $\vec{c}^\prime$ to construct a $\{\vec{a}_\text{nqbsclup}\}$
						\end{enumerate}

						This guarantees that all proposed $\{\vec{Z}\}$ obey the constraints, however the projection performed is somewhat naive and may sometimes be far away from the optimum. 

						However, since we are varying $\vec{a}_\text{nqblup}$ freely, it can move very far away from the optimum, and so it is possible to generate arbitrary constraint-obeying $\vec{a_\text{bsclup}}$ (i.e., although the projection of $\vec{a}_\text{blup}$ is not guaranteed to be near the optimum, if we set $\vec{a}_\text{nqblup} = \vec{a}_\text{bsclup}$, the projection would trivially be equal to $\vec{a}_\text{bsclup}$, and therefore small variations from this position will also be projected into small variations from the optimum.)

						This has the benefit of being able to explore arbitrary predictors (given enough time), without producing too many additional dimensions -- the downside is that since the projections may make many $\vec{a}_\text{nqblup}$ produce the same $\vec{a}_\text{bsclup}$ (and hence the same score), the MCMC might think it has redundant dimensions, get confused, or otherwise have an excessively high autocorrelation time as it struggles to find which parameters are meaningful.
					% \subsection{MCMC Errors}

					% I propose a different kind of error analysis, based on MCMC methods. The reasoning for this is that, by the nature of the kind of constraints we are trying to impose, it does not make sense to talk about the errors in each prediction as independent. This follows from our conversion from a local-MSE to the global Lagrangian: individual points might have a large individual error (i.e. a high-MSE), but which ensures a globally minimised error: does it make sense to assign this point a large error when it, in fact, cannot be moved without altering where every other point in the curve would be placed? 
		
					% In short: we are predicting \textit{curves} not points, and so it does not make sense to assign errors to individual points, but only to curves as a unit. 
		
					% The problem in doing so is that we need a set of parameters which can be varied in order to produce different values of $\mathcal{L}$, and hence compute the transition probabilities for the MCMC effort -- in the case of the optimised-CLUP (i.e. the monotonic constraint), we might naturally say that $\vec{c}$ is the obvious choice -- however this does not generalise to the exact-CLUP (i.e. the even or integrable), where we would have no functions to optimise -- it also suggests that the only source of error is in the optimisation - whereas `close but wrong' solutions should also arise in the BLP/BLUP/exact-CLUP case. 
		
					% We therefore suggest that the parameters to vary are the joint set $\vec{y} = (\vec{p}^\text{blup})$ - that is because this can define a unique predictor, through the following procedure:
		
					% \begin{enumerate}
					% 	\item Propose $\vec{p}_\text{blup}$
					% 	\item Segment the constraint into inexact ($\vec{c}^{(i)}$) and exact ($\vec{c}^(e)$)
					% 	\item Evaluate $D \vec{p}_\text{blup} = \tilde{c}$. 
					% 	\item Let $\vec{c}^\prime_i = \begin{cases} 
					% 		\tilde{c}_i & \text{if } \tilde{c}_i > m_i
					% 		\\
					% 		m_i & \text{else}
					% 	\end{cases}$
					% 	\item Set $\vec{a}_i^\text{blup-new} = \frac{p^\text{blup}}{p^\text{blup-old}} \vec{a}_i^\text{blup-old}$
					% 	\item Then:
					% 	$$ \ai^\text{clup} = \vec{a}_i^\text{blup-new} +  \frac{\left(D^T \left(D D^T \right)^{-1} \left(\vec{c}^\prime - D \vec{p}^\text{blup}\right)\right)\cdot \hat{e}_i}{\vec{X} \cdot K^{-1} \Delta\vec{X}} K^{-1} \Delta\vec{X}$$
					% \end{enumerate}
					% Step 4 is a quick-and-dirty mapping from a proposed curve to one which obeys the inexact constraints - recalling that our setup is such that we have formulated these constraints in terms of positive slack constraints: $g(\{p\}) \geq 0 \to g(\{p\}) = s^2$ -- in the case of `less than relations' ($g(\{p\})<0$) it is therefore important to formulate $D$ in terms of $-g$, such that it becomes a greater-than problem.
		
					
\end{document}